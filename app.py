import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.express as px
from rdkit import Chem
from rdkit.Chem import DataStructs, rdFingerprintGenerator
from rdkit.Chem.Scaffolds import MurckoScaffold
import sqlite3 # DB Ïó∞ÎèôÏùÑ ÏúÑÌï¥ Ï∂îÍ∞Ä
import json

# utils.pyÎ°úÎ∂ÄÌÑ∞ Î™®Îì† ÌïÑÏöîÌïú Ìï®ÏàòÎ•º ÏûÑÌè¨Ìä∏Ìï©ÎãàÎã§.
from utils import (
    load_data,
    find_activity_cliffs,
    generate_hypothesis_cliff,
    generate_hypothesis_quantitative,
    draw_highlighted_pair,
    check_stereoisomers,
    calculate_molecular_properties,
    get_structural_difference_keyword,
    save_results_to_db
)

# --- Ïô∏Î∂Ä ÏãúÏä§ÌÖú ÏûÑÌè¨Ìä∏ (ÏõêÎ≥∏Í≥º ÎèôÏùº) ---
try:
    from online_discussion_system import run_online_discussion_system
    ONLINE_DISCUSSION_AVAILABLE = True
    print("‚úÖ Co-Scientist Ïò®ÎùºÏù∏ ÌÜ†Î°† ÏãúÏä§ÌÖú Î°úÎìú ÏÑ±Í≥µ")
except ImportError as e:
    ONLINE_DISCUSSION_AVAILABLE = False
    print(f"‚ùå Co-Scientist Ïò®ÎùºÏù∏ ÌÜ†Î°† ÏãúÏä§ÌÖú Î°úÎìú Ïã§Ìå®: {str(e)}")

try:
    from llm_debate.debate.optimal_prompt_debate_manager import OptimalPromptDebateManager
    from streamlit_components.optimal_prompt_debate_interface import OptimalPromptDebateInterface
    PROMPT_SYSTEM_AVAILABLE = True
    print("‚úÖ ÏµúÏ†Å ÌîÑÎ°¨ÌîÑÌä∏ ÌÜ†Î°† ÏãúÏä§ÌÖú Î°úÎìú ÏÑ±Í≥µ")
except ImportError as e:
    PROMPT_SYSTEM_AVAILABLE = False
    print(f"‚ùå ÏµúÏ†Å ÌîÑÎ°¨ÌîÑÌä∏ ÌÜ†Î°† ÏãúÏä§ÌÖú Î°úÎìú Ïã§Ìå®: {str(e)}")

# --- ÌéòÏù¥ÏßÄ Í∏∞Î≥∏ ÏÑ§Ï†ï (ÏõêÎ≥∏Í≥º ÎèôÏùº) ---
st.set_page_config(page_title="AI Í∏∞Î∞ò SAR Î∂ÑÏÑù ÏãúÏä§ÌÖú", page_icon="üß™", layout="wide")


# --- Í≥µÌÜµ Î°úÏßÅ Ï≤òÎ¶¨ Ìó¨Ìçº Ìï®Ïàò (ÏõêÎ≥∏Í≥º ÎèôÏùº) ---
def process_and_display_pair(idx, cliff_data, sim_thresh, activity_col, tab_key, target_name, api_key, llm_provider):
    mol1 = pd.Series(cliff_data['mol_1'])
    mol2 = pd.Series(cliff_data['mol_2'])
    similarity = cliff_data['similarity']
    
    header = f"Ïåç #{idx+1} (ID: {mol1.get('ID', 'N/A')} vs {mol2.get('ID', 'N/A')}) | Ïú†ÏÇ¨ÎèÑ: {similarity:.3f}"
    
    with st.expander(header, expanded=True):
        real_act_diff = cliff_data['activity_diff']
        structural_diff = cliff_data['structural_difference']
        is_stereoisomer = cliff_data['is_stereoisomer']
        mol1_props = cliff_data['mol1_properties']
        mol2_props = cliff_data['mol2_properties']
        
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Tanimoto Ïú†ÏÇ¨ÎèÑ", f"{similarity:.3f}")
        c2.metric(f"Œî{activity_col}", f"{real_act_diff:.3f}")
        c3.metric("Íµ¨Ï°∞Ï†Å Ï∞®Ïù¥", structural_diff)
        c4.metric("ÏûÖÏ≤¥Ïù¥ÏÑ±ÏßàÏ≤¥", "Ïòà" if is_stereoisomer else "ÏïÑÎãàÏò§")

        with st.container():
            sub_c1, sub_c2, sub_c3 = st.columns(3)
            with sub_c1:
                st.metric(f"{mol1.get('ID', 'N/A')} Î∂ÑÏûêÎüâ", f"{mol1_props.get('molecular_weight', 0):.1f} Da")
                st.metric(f"{mol1.get('ID', 'N/A')} LogP", f"{mol1_props.get('logp', 0):.2f}")
            with sub_c2:
                st.metric(f"{mol2.get('ID', 'N/A')} Î∂ÑÏûêÎüâ", f"{mol2_props.get('molecular_weight', 0):.1f} Da")
                st.metric(f"{mol2.get('ID', 'N/A')} LogP", f"{mol2_props.get('logp', 0):.2f}")
            with sub_c3:
                mw_diff = abs(mol1_props.get('molecular_weight', 0) - mol2_props.get('molecular_weight', 0))
                logp_diff = abs(mol1_props.get('logp', 0) - mol2_props.get('logp', 0))
                st.metric("Î∂ÑÏûêÎüâ Ï∞®Ïù¥", f"{mw_diff:.1f} Da")
                st.metric("LogP Ï∞®Ïù¥", f"{logp_diff:.2f}")
        st.markdown("---")

        svg1, svg2 = draw_highlighted_pair(mol1['SMILES'], mol2['SMILES'])
        c1, c2 = st.columns(2)
        with c1:
            st.markdown(f"**ÌôîÌï©Î¨º 1: {mol1.get('ID', 'N/A')}**")
            metric_label_1 = f"{activity_col} ({mol1.get('Activity', 'N/A')})"
            metric_value_1 = f"{mol1.get(activity_col, 0):.3f}"
            st.metric(label=metric_label_1, value=metric_value_1)
            st.image(svg1, use_container_width=True)
        with c2:
            st.markdown(f"**ÌôîÌï©Î¨º 2: {mol2.get('ID', 'N/A')}**")
            metric_label_2 = f"{activity_col} ({mol2.get('Activity', 'N/A')})"
            metric_value_2 = f"{mol2.get(activity_col, 0):.3f}"
            st.metric(label=metric_label_2, value=metric_value_2)
            st.image(svg2, use_container_width=True)
        
        st.markdown("---")

        if tab_key.endswith('basic'):
            if st.button("AI Í∞ÄÏÑ§ ÏÉùÏÑ±", key=f"gen_hyp_{idx}_{tab_key}"):
                if not api_key: st.warning("ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú API ÌÇ§Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
                else:
                    with st.spinner("AI Í∞ÄÏÑ§ ÏÉùÏÑ± Ï§ë..."):
                        if tab_key.startswith('quantitative'):
                            hypothesis, context = generate_hypothesis_quantitative(mol1, mol2, similarity, target_name, api_key, llm_provider)
                        else: 
                            hypothesis, context = generate_hypothesis_cliff(cliff_data, target_name, api_key, llm_provider, activity_col)
                        st.markdown(hypothesis)
                        if context:
                            with st.expander("Ï∞∏Í≥† Î¨∏Ìóå Ï†ïÎ≥¥ (RAG)"): st.json(context)

        elif tab_key.endswith('advanced'):
        # --- [ÏàòÏ†ïÎêú Î∂ÄÎ∂Ñ ÏãúÏûë] ---
         if st.button("Ïò®ÎùºÏù∏ ÌÜ†Î°† ÏãúÏûë Î∞è Í≤∞Í≥º Ï†ÄÏû•", key=f"disc_{idx}_{tab_key}"):
            if not api_key: 
                st.warning("ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú API ÌÇ§Î•º ÏûÖÎ†•Ìï¥Ï£ºÏÑ∏Ïöî.")
            elif not ONLINE_DISCUSSION_AVAILABLE: 
                st.error("Ïò®ÎùºÏù∏ ÌÜ†Î°† ÏãúÏä§ÌÖú Î™®ÎìàÏùÑ Î°úÎìúÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
            else:
                with st.spinner("AI Ï†ÑÎ¨∏Í∞ÄÎì§Ïù¥ ÌÜ†Î°† ÌõÑ ÏµúÏ¢Ö Î¶¨Ìè¨Ìä∏Î•º ÏûëÏÑ±Ìï©ÎãàÎã§..."):
                    # 1. Ïò®ÎùºÏù∏ ÌÜ†Î°† ÏãúÏä§ÌÖú Ïã§ÌñâÌïòÏó¨ ÏµúÏ¢Ö Î¶¨Ìè¨Ìä∏ Î∞õÍ∏∞
                    final_report = run_online_discussion_system(cliff_data, target_name, api_key, llm_provider)
                    
                    st.markdown("### Ï†ÑÎ¨∏Í∞Ä ÌÜ†Î°† ÏµúÏ¢Ö Î¶¨Ìè¨Ìä∏")
                    st.json(final_report)

                    # 2. utilsÏùò Ìï®ÏàòÎ•º Ìò∏Ï∂úÌïòÏó¨ DBÏóê ÏµúÏ¢Ö Î¶¨Ìè¨Ìä∏ Ï†ÄÏû•
                    # final_reportÍ∞Ä dict ÌòïÌÉúÏùº Ïàò ÏûàÏúºÎØÄÎ°ú, json.dumpsÎ°ú ÌÖçÏä§Ìä∏ Î≥ÄÌôò
                    report_text = json.dumps(final_report, indent=2, ensure_ascii=False)
                    
                    saved_id = save_results_to_db(
                        db_path=db_path,
                        cliff_data=cliff_data,
                        hypothesis_text=report_text, # ÏµúÏ¢Ö Î¶¨Ìè¨Ìä∏Î•º Ï†ÄÏû•
                        llm_provider="Expert Discussion System", # ÏóêÏù¥Ï†ÑÌä∏ Ïù¥Î¶Ñ Î≥ÄÍ≤Ω
                        context_info=None # Î¶¨Ìè¨Ìä∏ ÏûêÏ≤¥Ïóê Ìè¨Ìï®Îêú Í≤ÉÏúºÎ°ú Í∞ÑÏ£º
                    )

                    if saved_id:
                        st.success(f"ÌÜ†Î°† Î¶¨Ìè¨Ìä∏Í∞Ä Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§Ïóê ÏÑ±Í≥µÏ†ÅÏúºÎ°ú Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§. (Analysis ID: {saved_id})")
                    else:
                        st.error("Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ Ï†ÄÏû•Ïóê Ïã§Ìå®ÌñàÏäµÎãàÎã§.")


# --- UI Î†åÎçîÎßÅ Ìï®Ïàò (ÏõêÎ≥∏Í≥º ÎèôÏùº) ---

def render_quantitative_analysis_ui(df, available_activity_cols, tab_key, target_name, api_key, llm_provider):
    st.info("Íµ¨Ï°∞Ï†ÅÏúºÎ°ú Ïú†ÏÇ¨ÌïòÏßÄÎßå **ÌôúÏÑ± Î∂ÑÎ•ò(Activity)Í∞Ä Îã§Î•∏** ÌôîÌï©Î¨º ÏåçÏùÑ ÌÉêÏÉâÌï©ÎãàÎã§.")
    if 'Activity' not in df.columns:
        st.error("Ïò§Î•ò: Ï†ïÎüâ Î∂ÑÏÑùÏùÑ Ïã§ÌñâÌïòÎ†§Î©¥ Îç∞Ïù¥ÌÑ∞Ïóê 'Activity' Ïª¨ÎüºÏù¥ ÌïÑÏöîÌï©ÎãàÎã§.")
        return
    if not available_activity_cols:
        st.error("Ïò§Î•ò: Î∂ÑÏÑùÏóê ÏÇ¨Ïö©Ìï† Ïú†Ìö®Ìïú ÌôúÏÑ± Ïª¨Îüº(pKi/pIC50)Ïù¥ Îç∞Ïù¥ÌÑ∞Ïóê ÏóÜÏäµÎãàÎã§.")
        return
    ref_activity_col = available_activity_cols[0]

    sim_thresh = st.slider("Ïú†ÏÇ¨ÎèÑ ÏûÑÍ≥ÑÍ∞í", 0.5, 1.0, 0.8, 0.01, key=f'sim_quant_{tab_key}')
    if st.button("Ï†ïÎüâ Î∂ÑÏÑù Ïã§Ìñâ", key=f'run_quant_{tab_key}'):
        with st.spinner("Ï†ïÎüâ Î∂ÑÏÑù Ï§ë..."):
            df_quant = df.dropna(subset=['SMILES', 'Activity', ref_activity_col]).copy()
            df_quant['mol'] = df_quant['SMILES'].apply(Chem.MolFromSmiles)
            df_quant.dropna(subset=['mol'], inplace=True)
            df_quant['scaffold'] = df_quant['mol'].apply(lambda m: Chem.MolToSmiles(MurckoScaffold.GetScaffoldForMol(m)) if m else None)
            fpgenerator = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)
            df_quant['fp'] = [fpgenerator.GetFingerprint(m) for m in df_quant['mol']]
            df_quant.reset_index(inplace=True, drop=True)
            pairs = []
            for i in range(len(df_quant)):
                for j in range(i + 1, len(df_quant)):
                    sim = DataStructs.TanimotoSimilarity(df_quant.iloc[i]['fp'], df_quant.iloc[j]['fp'])
                    if sim >= sim_thresh and df_quant.iloc[i]['Activity'] != df_quant.iloc[j]['Activity']:
                        pairs.append({'mol1_index': i, 'mol2_index': j, 'similarity': sim})
            activity_map = {'Highly Active': 4, 'Moderately Active': 3, 'Weakly Active': 2, 'Inactive': 1}
            for pair in pairs:
                activity1 = df_quant.iloc[pair['mol1_index']]['Activity']
                activity2 = df_quant.iloc[pair['mol2_index']]['Activity']
                score1 = activity_map.get(activity1, 0)
                score2 = activity_map.get(activity2, 0)
                pair['activity_category_diff'] = abs(score1 - score2)
            pairs.sort(key=lambda x: x.get('activity_category_diff', 0), reverse=True)
            st.session_state[f'quant_pairs_{tab_key}'] = pairs
            st.session_state[f'quant_data_{tab_key}'] = df_quant

    if f'quant_pairs_{tab_key}' in st.session_state:
        pairs = st.session_state[f'quant_pairs_{tab_key}']
        df_quant_valid = st.session_state[f'quant_data_{tab_key}']
        st.success(f"Ï¥ù {len(pairs)}Í∞úÏùò Ïú†ÏùòÎØ∏Ìïú ÌôîÌï©Î¨º ÏåçÏùÑ Ï∞æÏïòÏäµÎãàÎã§.")
        if not pairs:
            st.warning("ÌòÑÏû¨ Ï°∞Í±¥Ïóê ÎßûÎäî ÌôîÌï©Î¨º ÏåçÏùÑ Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§. ÏûÑÍ≥ÑÍ∞íÏùÑ Ï°∞Ï†àÌï¥Î≥¥ÏÑ∏Ïöî.")
        else:
            st.markdown("#### ÏÉÅÏÑ∏ Î∂ÑÏÑù Î™©Î°ù")
            pair_options = [
                f"{idx+1}. {df_quant_valid.iloc[p['mol1_index']].get('ID', 'N/A')} vs {df_quant_valid.iloc[p['mol2_index']].get('ID', 'N/A')} "
                f"(Ïú†ÏÇ¨ÎèÑ: {p['similarity']:.2f}, Î∂ÑÎ•òÏ∞®Ïù¥ Ï†êÏàò: {p.get('activity_category_diff', 0)})" 
                for idx, p in enumerate(pairs)
            ]
            selected_pair_str = st.selectbox("Î∂ÑÏÑùÌï† ÏåçÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî:", pair_options, key=f"pair_select_{tab_key}")
            if selected_pair_str:
                selected_idx = pair_options.index(selected_pair_str)
                pair_info = pairs[selected_idx]
                mol1 = df_quant_valid.iloc[pair_info['mol1_index']]
                mol2 = df_quant_valid.iloc[pair_info['mol2_index']]
                cliff_data_quant = {
                    'mol_1': mol1.to_dict(),
                    'mol_2': mol2.to_dict(),
                    'similarity': pair_info['similarity'],
                    'activity_diff': abs(mol1.get(ref_activity_col, 0) - mol2.get(ref_activity_col, 0)),
                    'structural_difference': get_structural_difference_keyword(mol1['SMILES'], mol2['SMILES']),
                    'is_stereoisomer': check_stereoisomers(mol1['SMILES'], mol2['SMILES']),
                    'mol1_properties': calculate_molecular_properties(mol1['mol']),
                    'mol2_properties': calculate_molecular_properties(mol2['mol']),
                    'same_scaffold': mol1.get('scaffold') == mol2.get('scaffold'),
                    'score': (abs(mol1.get(ref_activity_col, 0) - mol2.get(ref_activity_col, 0))) * (pair_info['similarity'] - sim_thresh) * (1 if mol1.get('scaffold') == mol2.get('scaffold') else 0.5)
                }
                process_and_display_pair(
                    idx=selected_idx, cliff_data=cliff_data_quant, sim_thresh=sim_thresh, 
                    activity_col=ref_activity_col, tab_key=f"quantitative_{tab_key}",
                    target_name=target_name, api_key=api_key, llm_provider=llm_provider
                )

def render_cliff_detection_ui(df, available_activity_cols, tab_key, target_name, api_key, llm_provider):
    st.info("Íµ¨Ï°∞Í∞Ä Ïú†ÏÇ¨ÌïòÏßÄÎßå **ÏÑ†ÌÉùÎêú ÌôúÏÑ± Í∞íÏùò Ï∞®Ïù¥Í∞Ä ÌÅ∞** Ïåç(Activity Cliff)ÏùÑ ÌÉêÏÉâÌï©ÎãàÎã§.")
    if not available_activity_cols:
        st.error("Ïò§Î•ò: Î∂ÑÏÑù Í∞ÄÎä•Ìïú ÌôúÏÑ± Ïª¨Îüº(pKi/pIC50)Ïù¥ ÏóÜÏäµÎãàÎã§.")
        return
    selected_col = st.selectbox("Î∂ÑÏÑù Í∏∞Ï§Ä Ïª¨Îüº ÏÑ†ÌÉù:", options=available_activity_cols, key=f'col_{tab_key}')
    with st.expander("ÌòÑÏû¨ Îç∞Ïù¥ÌÑ∞ ÌôúÏÑ±ÎèÑ Î∂ÑÌè¨ Î≥¥Í∏∞"):
        plot_df_dist = df.copy()
        plot_df_dist[selected_col] = pd.to_numeric(plot_df_dist[selected_col], errors='coerce')
        plot_df_dist.dropna(subset=[selected_col], inplace=True)
        if not plot_df_dist.empty:
            st.metric(label=f"Î∂ÑÏÑùÏóê ÏÇ¨Ïö©Îê† Ïú†Ìö® Îç∞Ïù¥ÌÑ∞ Í∞úÏàò", value=f"{len(plot_df_dist)} Í∞ú")
            display_cols = ['SMILES', 'Target', selected_col]
            st.dataframe(plot_df_dist[display_cols].head())
            fig_hist = px.histogram(plot_df_dist, x=selected_col, title=f'{selected_col} Í∞í Î∂ÑÌè¨', labels={selected_col: f'{selected_col} Í∞í'})
            st.plotly_chart(fig_hist, use_container_width=True, key=f"histogram_{tab_key}")
        else:
            st.warning(f"'{selected_col}' Ïª¨ÎüºÏóê Ïú†Ìö®Ìïú Îç∞Ïù¥ÌÑ∞Í∞Ä ÏóÜÏñ¥ Î∂ÑÌè¨Î•º ÌëúÏãúÌï† Ïàò ÏóÜÏäµÎãàÎã§.")
    c1, c2 = st.columns(2)
    with c1: sim_thresh = st.slider("Ïú†ÏÇ¨ÎèÑ ÏûÑÍ≥ÑÍ∞í", 0.5, 1.0, 0.8, 0.01, key=f'sim_{tab_key}')
    with c2: act_diff_thresh = st.slider(f"Œî{selected_col} ÏûÑÍ≥ÑÍ∞í", 0.1, 5.0, 1.0, 0.1, key=f'act_{tab_key}')
    if st.button("ÌôúÏÑ± Ï†àÎ≤Ω ÌÉêÏßÄ Ïã§Ìñâ", key=f'run_cliff_{tab_key}'):
        with st.spinner("ÌôúÏÑ± Ï†àÎ≤Ω Î∂ÑÏÑù Ï§ë..."):
            cliffs = find_activity_cliffs(df, sim_thresh, act_diff_thresh, selected_col)
            st.session_state[f'cliffs_{tab_key}'] = cliffs
            st.session_state[f'analyzed_col_{tab_key}'] = selected_col

    if f'cliffs_{tab_key}' in st.session_state:
        cliffs = st.session_state[f'cliffs_{tab_key}']
        analyzed_col = st.session_state.get(f'analyzed_col_{tab_key}', selected_col)
        st.success(f"Ï¥ù {len(cliffs)}Í∞úÏùò ÌôúÏÑ± Ï†àÎ≤Ω ÏåçÏùÑ Ï∞æÏïòÏäµÎãàÎã§.")
        if cliffs:
            plot_df_scatter = pd.DataFrame(cliffs)
            plot_df_scatter['pair_label'] = plot_df_scatter.apply(
                lambda row: f"{row['mol_1'].get('ID', 'N/A')} vs {row['mol_2'].get('ID', 'N/A')}", axis=1
            )
            st.markdown("#### Activity Cliff Î∂ÑÌè¨ ÏãúÍ∞ÅÌôî")
            fig_scatter = px.scatter(
                plot_df_scatter,
                x='similarity',
                y='activity_diff', 
                title='Activity Cliff Î∂ÑÌè¨ (Ïö∞Ï∏° ÏÉÅÎã®Ïù¥ Í∞ÄÏû• Ïú†ÏùòÎØ∏Ìïú ÏòÅÏó≠)',
                labels={'similarity': 'Íµ¨Ï°∞ Ïú†ÏÇ¨ÎèÑ (Tanimoto)', 'activity_diff': f'ÌôúÏÑ±ÎèÑ Ï∞®Ïù¥ (Œî{analyzed_col})'}, # <<< Ïó¨Í∏∞ÎèÑ ÏàòÏ†ï
                hover_data=['pair_label', 'score'],
                color='score',
                color_continuous_scale=px.colors.sequential.Viridis,
                size='activity_diff' # <<< Ïó¨Í∏∞ÎèÑ ÏàòÏ†ï
            )
            fig_scatter.add_shape(
                type="rect", xref="x", yref="y",
                x0=sim_thresh, y0=act_diff_thresh, x1=1.0, 
                y1=plot_df_scatter['activity_diff'].max() * 1.1, # <<< Ïó¨Í∏∞Î•º ÏàòÏ†ï
                line=dict(color="Red", width=2, dash="dash"),
                fillcolor="rgba(255,0,0,0.1)"
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
            st.markdown("---")
        if not cliffs:
            st.warning("ÌòÑÏû¨ Ï°∞Í±¥Ïóê ÎßûÎäî ÌôúÏÑ± Ï†àÎ≤ΩÏùÑ Ï∞æÏßÄ Î™ªÌñàÏäµÎãàÎã§. ÏûÑÍ≥ÑÍ∞íÏùÑ Ï°∞Ï†àÌï¥Î≥¥ÏÑ∏Ïöî.")
        else:
            st.markdown("#### ÏÉÅÏÑ∏ Î∂ÑÏÑù Î™©Î°ù")
            pair_options = [
                f"{idx+1}. {c['mol_1'].get('ID', 'N/A')} vs {c['mol_2'].get('ID', 'N/A')} "
                f"(Ïú†ÏÇ¨ÎèÑ: {c['similarity']:.2f}, ÌôúÏÑ±Ï∞®Ïù¥: {c['activity_diff']:.2f})"
                for idx, c in enumerate(cliffs)
            ]
            selected_pair_str = st.selectbox("Î∂ÑÏÑùÌï† ÏåçÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî:", pair_options, key=f"pair_select_{tab_key}")
            if selected_pair_str:
                selected_idx = pair_options.index(selected_pair_str)
                cliff = cliffs[selected_idx]
                process_and_display_pair(
                    idx=selected_idx, cliff_data=cliff, sim_thresh=sim_thresh, 
                    activity_col=analyzed_col, tab_key=tab_key,
                    target_name=target_name, api_key=api_key, llm_provider=llm_provider
                )


# --- [ÏàòÏ†ï ÏãúÏûë] DB Ïó∞ÎèôÏùÑ ÏúÑÌïú Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ìï®Ïàò ---
db_path = "/Users/lionkim/Downloads/project_archive/sar-project/patent_etl_pipeline/database/patent_data.db" 

@st.cache_data
def get_target_list(database_path):
    """DBÏùò targets ÌÖåÏù¥Î∏îÏóêÏÑú Ï†ÑÏ≤¥ ÌÉÄÍ≤ü Ïù¥Î¶Ñ Î™©Î°ùÎßå Îπ†Î•¥Í≤å Í∞ÄÏ†∏ÏòµÎãàÎã§."""
    if not os.path.exists(database_path):
        st.sidebar.error(f"DB ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {database_path}")
        return []
    try:
        conn = sqlite3.connect(database_path, check_same_thread=False)
        # targets ÌÖåÏù¥Î∏îÏóêÏÑú target_nameÎßå Ï°∞Ìöå
        query = "SELECT target_name FROM targets ORDER BY target_name;"
        df = pd.read_sql_query(query, conn)
        return df['target_name'].tolist()
    except Exception as e:
        st.sidebar.error(f"DB ÌÉÄÍ≤ü Î™©Î°ù Î°úÎî© Ï§ë Ïò§Î•ò: {e}")
        return []
    finally:
        if 'conn' in locals() and conn:
            conn.close()

@st.cache_data
def get_data_for_target(database_path, target_name):
    """ÏÇ¨Ïö©ÏûêÍ∞Ä ÏÑ†ÌÉùÌïú ÌäπÏ†ï ÌÉÄÍ≤üÏùò Îç∞Ïù¥ÌÑ∞Îßå DBÏóêÏÑú JOINÌïòÏó¨ Î°úÎìúÌï©ÎãàÎã§."""
    if not os.path.exists(database_path): return None
    try:
        conn = sqlite3.connect(database_path, check_same_thread=False)
        # Ï†úÍ≥µÌï¥Ï£ºÏã† ÏøºÎ¶¨Ïóê WHERE Ï†àÏùÑ Ï∂îÍ∞ÄÌïòÏó¨ ÌäπÏ†ï ÌÉÄÍ≤ü Îç∞Ïù¥ÌÑ∞Îßå ÏÑ†ÌÉù
        query = """
        SELECT
            c.smiles AS "SMILES",
            t.target_name AS "Target",
            a.pic50 AS "pIC50",
            a.ic50 AS "IC50",
            a.activity_category AS "Activity",
            c.compound_id AS "ID"
        FROM activities a
        JOIN compounds c ON a.compound_id = c.compound_id
        JOIN targets t ON a.target_id = t.target_id
        WHERE t.target_name = ?;
        """
        # SQL Injection Í≥µÍ≤© Î∞©ÏßÄÎ•º ÏúÑÌï¥ ÌååÎùºÎØ∏ÌÑ∞Î•º ÏÇ¨Ïö©ÌïòÏó¨ ÏïàÏ†ÑÌïòÍ≤å ÏøºÎ¶¨ Ïã§Ìñâ
        df = pd.read_sql_query(query, conn, params=(target_name,))
        return df
    except Exception as e:
        st.error(f"'{target_name}' Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ë Ïò§Î•ò: {e}")
        return None
    finally:
        if 'conn' in locals() and conn:
            conn.close()

@st.cache_data
def get_data_from_db(database_path):
    """SQLite Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú Îç∞Ïù¥ÌÑ∞Î•º Î°úÎìúÌï©ÎãàÎã§."""
    if not os.path.exists(database_path):
        st.sidebar.error(f"DB ÌååÏùºÏùÑ Ï∞æÏùÑ Ïàò ÏóÜÏäµÎãàÎã§: {database_path}")
        return None
    try:
        conn = sqlite3.connect(database_path, check_same_thread=False)
        # ÏõêÎ≥∏ utils.pyÏùò load_dataÍ∞Ä Ï≤òÎ¶¨ÌïòÎäî Ïª¨ÎüºÎì§ÏùÑ Î™®Îëê Í∞ÄÏ†∏ÏòµÎãàÎã§.
        # Ïª¨ÎüºÎ™ÖÏùÑ ÏõêÎ≥∏ load_data Ìï®ÏàòÍ∞Ä Í∏∞ÎåÄÌïòÎäî ÌòïÏãùÍ≥º Ïú†ÏÇ¨ÌïòÍ≤å ÎßûÏ∂∞Ï§çÎãàÎã§.
        query = """
        SELECT
            c.smiles AS "SMILES",
            t.target_name AS "Target",
            a.pic50 AS "pIC50",
            a.ic50 AS "IC50",
            a.activity_category AS "Activity",
            c.compound_id AS "ID"
        FROM activities a
        JOIN compounds c ON a.compound_id = c.compound_id
        JOIN targets t ON a.target_id = t.target_id;
        """
        df = pd.read_sql_query(query, conn)
        return df
    except Exception as e:
        st.sidebar.error(f"DB Î°úÎî© Ï§ë Ïò§Î•ò: {e}")
        return None
    finally:
        if 'conn' in locals() and conn:
            conn.close()
# --- [ÏàòÏ†ï ÎÅù] ---


# --- Main App ---
def main():
    with st.sidebar:
        st.title("AI SAR Î∂ÑÏÑù ÏãúÏä§ÌÖú")
        st.info("AI Í∏∞Î∞ò Íµ¨Ï°∞-ÌôúÏÑ± Í¥ÄÍ≥Ñ(SAR) Î∂ÑÏÑù Î∞è ÏòàÏ∏° ÏÜîÎ£®ÏÖòÏûÖÎãàÎã§.")
        
        st.header("üìÅ Îç∞Ïù¥ÌÑ∞ ÏÑ†ÌÉù")
        
        # 1Îã®Í≥Ñ: Ï†ÑÏ≤¥ ÌÉÄÍ≤ü Î™©Î°ùÎßå Îπ†Î•¥Í≤å Î°úÎìúÌïòÏó¨ SelectboxÎ•º ÏÉùÏÑ±Ìï©ÎãàÎã§.
        target_list = get_target_list(db_path)
        selected_target = None
        
        if target_list:
            selected_target = st.selectbox('Î∂ÑÏÑùÌï† ÌÉÄÍ≤ü ÏÑ†ÌÉù', target_list)
        else:
            st.warning("Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ÏóêÏÑú ÌÉÄÍ≤ü Î™©Î°ùÏùÑ Î∂àÎü¨Ïò¨ Ïàò ÏóÜÏäµÎãàÎã§.")

        st.header("‚öôÔ∏è AI Î™®Îç∏ ÏÑ§Ï†ï")
        # target_name_inputÏùÄ Ïù¥Ï†ú Í∏∞Î≥∏Í∞í ÎòêÎäî Î≥¥Ï°∞ Ïö©ÎèÑÎ°úÎßå ÏÇ¨Ïö©Îê©ÎãàÎã§.
        target_name_input = st.text_input("Î∂ÑÏÑù ÎåÄÏÉÅ ÌÉÄÍ≤ü Îã®Î∞±Ïßà (Ï∞∏Í≥†Ïö©)", value=selected_target or "EGFR")
        llm_provider = st.selectbox("LLM Í≥µÍ∏âÏûê ÏÑ†ÌÉù:", ("OpenAI", "Gemini"))
        api_key = st.text_input("API ÌÇ§ ÏûÖÎ†•:", type="password", placeholder="OpenAI ÎòêÎäî Gemini API ÌÇ§")

    st.header("Î∂ÑÏÑù Í≤∞Í≥º ÎåÄÏãúÎ≥¥Îìú")
    df, available_activity_cols = None, []
    
    # 2Îã®Í≥Ñ: ÏÇ¨Ïö©ÏûêÍ∞Ä ÌÉÄÍ≤üÏùÑ ÏÑ†ÌÉùÌïú Í≤ΩÏö∞ÏóêÎßå Ìï¥Îãπ Îç∞Ïù¥ÌÑ∞Î•º DBÏóêÏÑú Î°úÎìúÌï©ÎãàÎã§.
    if selected_target:
        with st.spinner(f"'{selected_target}' Îç∞Ïù¥ÌÑ∞ Î°úÎî© Ï§ë..."):
            # ÌäπÏ†ï ÌÉÄÍ≤üÏùò Îç∞Ïù¥ÌÑ∞Îßå DBÏóêÏÑú Í∞ÄÏ†∏ÏòµÎãàÎã§.
            df_from_db = get_data_for_target(db_path, selected_target)
        
        if df_from_db is not None:
            # 3Îã®Í≥Ñ: Î°úÎìúÎêú Îç∞Ïù¥ÌÑ∞Î•º ÌõÑÏ≤òÎ¶¨ Ìï®Ïàò(utils.pyÏùò load_data)Î°ú Ï†ÑÎã¨Ìï©ÎãàÎã§.
            df_processed, available_activity_cols = load_data(df_from_db)

            if df_processed is not None:
                # --- [ÏàòÏ†ïÎêú Î∂ÄÎ∂Ñ ÏãúÏûë] ---
                # Ïù¥ Îã®Í≥ÑÏóêÏÑú ÎØ∏Î¶¨ Ï§ëÎ≥µÏùÑ Ï†úÍ±∞Ìï©ÎãàÎã§.
                ref_col = available_activity_cols[0] if available_activity_cols else 'pIC50'
                if ref_col in df_processed.columns:
                    # 1. ÌôúÏÑ±ÎèÑÍ∞Ä ÎÜíÏùÄ ÏàúÏúºÎ°ú Ï†ïÎ†¨
                    df_sorted = df_processed.sort_values(ref_col, ascending=False)
                    # 2. SMILES Í∏∞Ï§Ä Ï§ëÎ≥µ Ï†úÍ±∞ (Í∞ÄÏû• ÌôúÏÑ±ÎèÑ ÎÜíÏùÄ Îç∞Ïù¥ÌÑ∞Îßå ÎÇ®ÍπÄ)
                    df = df_sorted.drop_duplicates(subset=['SMILES'], keep='first')
                else:
                    df = df_processed.drop_duplicates(subset=['SMILES'], keep='first')
                
                st.sidebar.success(f"Ï¥ù {len(df_from_db)}Í∞ú Îç∞Ïù¥ÌÑ∞ Ï§ë {len(df)}Í∞úÏùò Í≥†Ïú† ÌôîÌï©Î¨º Î°úÎìú ÏôÑÎ£å!")
                # --- [ÏàòÏ†ïÎêú Î∂ÄÎ∂Ñ ÎÅù] ---
            
            # Activity Ïª¨ÎüºÏù¥ ÏóÜÎäî Í≤ΩÏö∞, pKi/pIC50 Í∏∞Ï§ÄÏúºÎ°ú ÏûêÎèô ÏÉùÏÑ±Ìï©ÎãàÎã§.
            if df is not None and 'Activity' not in df.columns and any(col in df.columns for col in ['pKi', 'pIC50']):
                ref_col = 'pKi' if 'pKi' in df.columns else 'pIC50'
                conditions = [
                    (df[ref_col] > 7.0),
                    (df[ref_col] > 5.7) & (df[ref_col] <= 7.0),
                    (df[ref_col] > 5.0) & (df[ref_col] <= 5.7),
                    (df[ref_col] <= 5.0) | (df[ref_col].isna())
                ]
                labels = ['Highly Active', 'Moderately Active', 'Weakly Active', 'Inactive']
                df['Activity'] = np.select(conditions, labels, default='Unclassified')
                st.info("Info: pKi/pIC50 Í∞íÏùÑ Í∏∞Ï§ÄÏúºÎ°ú Activity Ïª¨ÎüºÏùÑ ÏÉàÎ°ú ÏÉùÏÑ±ÌñàÏäµÎãàÎã§.")

    # 4Îã®Í≥Ñ: ÏµúÏ¢Ö Ï≤òÎ¶¨Îêú Îç∞Ïù¥ÌÑ∞(df)Í∞Ä ÏûàÏùÑ Í≤ΩÏö∞ÏóêÎßå Î∂ÑÏÑù ÌÉ≠Îì§ÏùÑ Î†åÎçîÎßÅÌï©ÎãàÎã§.
    if df is not None:
        st.success(f"'{selected_target}'Ïóê ÎåÄÌïú {len(df)}Í∞úÏùò ÌôîÌï©Î¨º Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Ï§ÄÎπÑ ÏôÑÎ£å!")
        
        tabs_to_create = []
        if ONLINE_DISCUSSION_AVAILABLE: tabs_to_create.append("SAR Î∂ÑÏÑù (ÌÜ†Î°† ÏãúÏä§ÌÖú Ï†ÅÏö©)")
        tabs_to_create.append("SAR Î∂ÑÏÑù (Í∏∞Î≥∏)")
        if PROMPT_SYSTEM_AVAILABLE: tabs_to_create.append("ÏµúÏ†Å ÌîÑÎ°¨ÌîÑÌä∏ ÌÜ†Î°†")
        
        created_tabs = st.tabs(tabs_to_create)
        tab_map = {name: tab for name, tab in zip(tabs_to_create, created_tabs)}
        
        tab_advanced = tab_map.get("SAR Î∂ÑÏÑù (ÌÜ†Î°† ÏãúÏä§ÌÖú Ï†ÅÏö©)")
        tab_basic = tab_map.get("SAR Î∂ÑÏÑù (Í∏∞Î≥∏)")
        tab_prompt = tab_map.get("ÏµúÏ†Å ÌîÑÎ°¨ÌîÑÌä∏ ÌÜ†Î°†")

        # Î∂ÑÏÑù Ìï®ÏàòÏóê Ï†ÑÎã¨Ìï† ÌÉÄÍ≤ü Ïù¥Î¶ÑÏùÄ Ïù¥Ï†ú ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú ÏÑ†ÌÉùÎêú Í∞íÏùÑ ÏÇ¨Ïö©Ìï©ÎãàÎã§.
        target_name_to_use = selected_target

        if tab_advanced:
            with tab_advanced:
                st.subheader("Íµ¨Ï°∞-ÌôúÏÑ± Í¥ÄÍ≥Ñ Î∂ÑÏÑù (ÌÜ†Î°† ÏãúÏä§ÌÖú Ï†ÅÏö©)")
                analysis_type_adv = st.radio("Î∂ÑÏÑù Ïú†Ìòï ÏÑ†ÌÉù:", ("ÌôúÏÑ± Ï†àÎ≤Ω ÌÉêÏßÄ", "Ï†ïÎüâ Î∂ÑÏÑù"), horizontal=True, key="adv_type")
                st.markdown("---")
                if analysis_type_adv == "Ï†ïÎüâ Î∂ÑÏÑù":
                    render_quantitative_analysis_ui(df, available_activity_cols, 'advanced', target_name_to_use, api_key, llm_provider)
                else:
                    render_cliff_detection_ui(df, available_activity_cols, 'advanced', target_name_to_use, api_key, llm_provider)
        
        if tab_basic:
            with tab_basic:
                st.subheader("Íµ¨Ï°∞-ÌôúÏÑ± Í¥ÄÍ≥Ñ Î∂ÑÏÑù (Í∏∞Î≥∏)")
                analysis_type_basic = st.radio("Î∂ÑÏÑù Ïú†Ìòï ÏÑ†ÌÉù:", ("ÌôúÏÑ± Ï†àÎ≤Ω ÌÉêÏßÄ", "Ï†ïÎüâ Î∂ÑÏÑù"), horizontal=True, key="basic_type")
                st.markdown("---")
                if analysis_type_basic == "Ï†ïÎüâ Î∂ÑÏÑù":
                    render_quantitative_analysis_ui(df, available_activity_cols, 'basic', target_name_to_use, api_key, llm_provider)
                else:
                    render_cliff_detection_ui(df, available_activity_cols, 'basic', target_name_to_use, api_key, llm_provider)

        if tab_prompt:
            with tab_prompt:
                st.markdown("# ÏµúÏ†Å ÌîÑÎ°¨ÌîÑÌä∏ ÌÜ†Î°† ÏãúÏä§ÌÖú")
                # (Ïù¥Ìïò ÌîÑÎ°¨ÌîÑÌä∏ ÌÜ†Î°† ÌÉ≠ Î°úÏßÅÏùÄ Í∏∞Ï°¥Í≥º ÎèôÏùº)
    else:
        st.info("Î∂ÑÏÑùÏùÑ ÏãúÏûëÌïòÎ†§Î©¥ ÏÇ¨Ïù¥ÎìúÎ∞îÏóêÏÑú Î∂ÑÏÑùÌï† ÌÉÄÍ≤üÏùÑ ÏÑ†ÌÉùÌïòÏÑ∏Ïöî.")

if __name__ == "__main__":
    main()

