import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.express as px
from rdkit import Chem
from rdkit.Chem import DataStructs, rdFingerprintGenerator
from rdkit.Chem.Scaffolds import MurckoScaffold
import sqlite3 # DB ì—°ë™ì„ ìœ„í•´ ì¶”ê°€
import json

# utils.pyë¡œë¶€í„° ëª¨ë“  í•„ìš”í•œ í•¨ìˆ˜ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from utils import (
    load_data,
    find_activity_cliffs,
    generate_hypothesis_cliff,
    generate_hypothesis_quantitative,
    draw_highlighted_pair,
    check_stereoisomers,
    calculate_molecular_properties,
    get_structural_difference_keyword,
    save_results_to_db
)

# --- ì™¸ë¶€ ì‹œìŠ¤í…œ ì„í¬íŠ¸ (ì›ë³¸ê³¼ ë™ì¼) ---
try:
    from online_discussion_system import run_online_discussion_system
    ONLINE_DISCUSSION_AVAILABLE = True
    print("âœ… Co-Scientist ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    ONLINE_DISCUSSION_AVAILABLE = False
    print(f"âŒ Co-Scientist ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

try:
    from llm_debate.debate.optimal_prompt_debate_manager import OptimalPromptDebateManager
    from streamlit_components.optimal_prompt_debate_interface import OptimalPromptDebateInterface
    PROMPT_SYSTEM_AVAILABLE = True
    print("âœ… ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    PROMPT_SYSTEM_AVAILABLE = False
    print(f"âŒ ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (ì›ë³¸ê³¼ ë™ì¼) ---
st.set_page_config(page_title="AI ê¸°ë°˜ SAR ë¶„ì„ ì‹œìŠ¤í…œ", page_icon="ğŸ§ª", layout="wide")


# --- ê³µí†µ ë¡œì§ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ (ì›ë³¸ê³¼ ë™ì¼) ---
def process_and_display_pair(idx, cliff_data, sim_thresh, activity_col, tab_key, target_name, api_key, llm_provider):
    mol1 = pd.Series(cliff_data['mol_1'])
    mol2 = pd.Series(cliff_data['mol_2'])
    similarity = cliff_data['similarity']
    
    header = f"ìŒ #{idx+1} (ID: {mol1.get('ID', 'N/A')} vs {mol2.get('ID', 'N/A')}) | ìœ ì‚¬ë„: {similarity:.3f}"
    
    with st.expander(header, expanded=True):
        real_act_diff = cliff_data['activity_diff']
        structural_diff = cliff_data['structural_difference']
        is_stereoisomer = cliff_data['is_stereoisomer']
        mol1_props = cliff_data['mol1_properties']
        mol2_props = cliff_data['mol2_properties']
        
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Tanimoto ìœ ì‚¬ë„", f"{similarity:.3f}")
        c2.metric(f"Î”{activity_col}", f"{real_act_diff:.3f}")
        c3.metric("êµ¬ì¡°ì  ì°¨ì´", structural_diff)
        c4.metric("ì…ì²´ì´ì„±ì§ˆì²´", "ì˜ˆ" if is_stereoisomer else "ì•„ë‹ˆì˜¤")

        with st.container():
            sub_c1, sub_c2, sub_c3 = st.columns(3)
            with sub_c1:
                st.metric(f"{mol1.get('ID', 'N/A')} ë¶„ìëŸ‰", f"{mol1_props.get('molecular_weight', 0):.1f} Da")
                st.metric(f"{mol1.get('ID', 'N/A')} LogP", f"{mol1_props.get('logp', 0):.2f}")
            with sub_c2:
                st.metric(f"{mol2.get('ID', 'N/A')} ë¶„ìëŸ‰", f"{mol2_props.get('molecular_weight', 0):.1f} Da")
                st.metric(f"{mol2.get('ID', 'N/A')} LogP", f"{mol2_props.get('logp', 0):.2f}")
            with sub_c3:
                mw_diff = abs(mol1_props.get('molecular_weight', 0) - mol2_props.get('molecular_weight', 0))
                logp_diff = abs(mol1_props.get('logp', 0) - mol2_props.get('logp', 0))
                st.metric("ë¶„ìëŸ‰ ì°¨ì´", f"{mw_diff:.1f} Da")
                st.metric("LogP ì°¨ì´", f"{logp_diff:.2f}")
        st.markdown("---")

        svg1, svg2 = draw_highlighted_pair(mol1['SMILES'], mol2['SMILES'])
        c1, c2 = st.columns(2)
        with c1:
            st.markdown(f"**í™”í•©ë¬¼ 1: {mol1.get('ID', 'N/A')}**")
            metric_label_1 = f"{activity_col} ({mol1.get('Activity', 'N/A')})"
            metric_value_1 = f"{mol1.get(activity_col, 0):.3f}"
            st.metric(label=metric_label_1, value=metric_value_1)
            st.image(svg1, use_container_width=True)
        with c2:
            st.markdown(f"**í™”í•©ë¬¼ 2: {mol2.get('ID', 'N/A')}**")
            metric_label_2 = f"{activity_col} ({mol2.get('Activity', 'N/A')})"
            metric_value_2 = f"{mol2.get(activity_col, 0):.3f}"
            st.metric(label=metric_label_2, value=metric_value_2)
            st.image(svg2, use_container_width=True)
        
        st.markdown("---")

        if tab_key.endswith('basic'):
            if st.button("AI ê°€ì„¤ ìƒì„±", key=f"gen_hyp_{idx}_{tab_key}"):
                if not api_key: st.warning("ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("AI ê°€ì„¤ ìƒì„± ì¤‘..."):
                        if tab_key.startswith('quantitative'):
                            hypothesis, context = generate_hypothesis_quantitative(mol1, mol2, similarity, target_name, api_key, llm_provider)
                        else: 
                            hypothesis, context = generate_hypothesis_cliff(cliff_data, target_name, api_key, llm_provider, activity_col)
                        st.markdown(hypothesis)
                        if context:
                            with st.expander("ì°¸ê³  ë¬¸í—Œ ì •ë³´ (RAG)"): st.json(context)

        elif tab_key.endswith('advanced'):
        # --- [ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘] ---
         if st.button("ì˜¨ë¼ì¸ í† ë¡  ì‹œì‘ ë° ê²°ê³¼ ì €ì¥", key=f"disc_{idx}_{tab_key}"):
            if not api_key: 
                st.warning("ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            elif not ONLINE_DISCUSSION_AVAILABLE: 
                st.error("ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                with st.spinner("AI ì „ë¬¸ê°€ë“¤ì´ í† ë¡  í›„ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤..."):
                    # 1. ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ ì‹¤í–‰í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ë°›ê¸°
                    final_report = run_online_discussion_system(cliff_data, target_name, api_key, llm_provider)
                    
                    st.markdown("### ì „ë¬¸ê°€ í† ë¡  ìµœì¢… ë¦¬í¬íŠ¸")
                    st.json(final_report)

                    # 2. utilsì˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ DBì— ìµœì¢… ë¦¬í¬íŠ¸ ì €ì¥
                    # final_reportê°€ dict í˜•íƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, json.dumpsë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
                    report_text = json.dumps(final_report, indent=2, ensure_ascii=False)
                    
                    saved_id = save_results_to_db(
                        db_path=db_path,
                        cliff_data=cliff_data,
                        hypothesis_text=report_text, # ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì €ì¥
                        llm_provider="Expert Discussion System", # ì—ì´ì „íŠ¸ ì´ë¦„ ë³€ê²½
                        context_info=None # ë¦¬í¬íŠ¸ ìì²´ì— í¬í•¨ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                    )

                    if saved_id:
                        st.success(f"í† ë¡  ë¦¬í¬íŠ¸ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (Analysis ID: {saved_id})")
                    else:
                        st.error("ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


# --- UI ë Œë”ë§ í•¨ìˆ˜ (ì›ë³¸ê³¼ ë™ì¼) ---

def render_quantitative_analysis_ui(df, available_activity_cols, tab_key, target_name, api_key, llm_provider):
    st.info("êµ¬ì¡°ì ìœ¼ë¡œ ìœ ì‚¬í•˜ì§€ë§Œ **í™œì„± ë¶„ë¥˜(Activity)ê°€ ë‹¤ë¥¸** í™”í•©ë¬¼ ìŒì„ íƒìƒ‰í•©ë‹ˆë‹¤.")
    if 'Activity' not in df.columns:
        st.error("ì˜¤ë¥˜: ì •ëŸ‰ ë¶„ì„ì„ ì‹¤í–‰í•˜ë ¤ë©´ ë°ì´í„°ì— 'Activity' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    if not available_activity_cols:
        st.error("ì˜¤ë¥˜: ë¶„ì„ì— ì‚¬ìš©í•  ìœ íš¨í•œ í™œì„± ì»¬ëŸ¼(pKi/pIC50)ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤.")
        return
    ref_activity_col = available_activity_cols[0]

    sim_thresh = st.slider("ìœ ì‚¬ë„ ì„ê³„ê°’", 0.5, 1.0, 0.8, 0.01, key=f'sim_quant_{tab_key}')
    if st.button("ì •ëŸ‰ ë¶„ì„ ì‹¤í–‰", key=f'run_quant_{tab_key}'):
        with st.spinner("ì •ëŸ‰ ë¶„ì„ ì¤‘..."):
            df_quant = df.dropna(subset=['SMILES', 'Activity', ref_activity_col]).copy()
            df_quant['mol'] = df_quant['SMILES'].apply(Chem.MolFromSmiles)
            df_quant.dropna(subset=['mol'], inplace=True)
            df_quant['scaffold'] = df_quant['mol'].apply(lambda m: Chem.MolToSmiles(MurckoScaffold.GetScaffoldForMol(m)) if m else None)
            fpgenerator = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)
            df_quant['fp'] = [fpgenerator.GetFingerprint(m) for m in df_quant['mol']]
            df_quant.reset_index(inplace=True, drop=True)
            pairs = []
            for i in range(len(df_quant)):
                for j in range(i + 1, len(df_quant)):
                    sim = DataStructs.TanimotoSimilarity(df_quant.iloc[i]['fp'], df_quant.iloc[j]['fp'])
                    if sim >= sim_thresh and df_quant.iloc[i]['Activity'] != df_quant.iloc[j]['Activity']:
                        pairs.append({'mol1_index': i, 'mol2_index': j, 'similarity': sim})
            activity_map = {'Highly Active': 4, 'Moderately Active': 3, 'Weakly Active': 2, 'Inactive': 1}
            for pair in pairs:
                activity1 = df_quant.iloc[pair['mol1_index']]['Activity']
                activity2 = df_quant.iloc[pair['mol2_index']]['Activity']
                score1 = activity_map.get(activity1, 0)
                score2 = activity_map.get(activity2, 0)
                pair['activity_category_diff'] = abs(score1 - score2)
            pairs.sort(key=lambda x: x.get('activity_category_diff', 0), reverse=True)
            st.session_state[f'quant_pairs_{tab_key}'] = pairs
            st.session_state[f'quant_data_{tab_key}'] = df_quant

    if f'quant_pairs_{tab_key}' in st.session_state:
        pairs = st.session_state[f'quant_pairs_{tab_key}']
        df_quant_valid = st.session_state[f'quant_data_{tab_key}']
        st.success(f"ì´ {len(pairs)}ê°œì˜ ìœ ì˜ë¯¸í•œ í™”í•©ë¬¼ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        if not pairs:
            st.warning("í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” í™”í•©ë¬¼ ìŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì„ê³„ê°’ì„ ì¡°ì ˆí•´ë³´ì„¸ìš”.")
        else:
            st.markdown("#### ìƒì„¸ ë¶„ì„ ëª©ë¡")
            pair_options = [
                f"{idx+1}. {df_quant_valid.iloc[p['mol1_index']].get('ID', 'N/A')} vs {df_quant_valid.iloc[p['mol2_index']].get('ID', 'N/A')} "
                f"(ìœ ì‚¬ë„: {p['similarity']:.2f}, ë¶„ë¥˜ì°¨ì´ ì ìˆ˜: {p.get('activity_category_diff', 0)})" 
                for idx, p in enumerate(pairs)
            ]
            selected_pair_str = st.selectbox("ë¶„ì„í•  ìŒì„ ì„ íƒí•˜ì„¸ìš”:", pair_options, key=f"pair_select_{tab_key}")
            if selected_pair_str:
                selected_idx = pair_options.index(selected_pair_str)
                pair_info = pairs[selected_idx]
                mol1 = df_quant_valid.iloc[pair_info['mol1_index']]
                mol2 = df_quant_valid.iloc[pair_info['mol2_index']]
                cliff_data_quant = {
                    'mol_1': mol1.to_dict(),
                    'mol_2': mol2.to_dict(),
                    'similarity': pair_info['similarity'],
                    'activity_diff': abs(mol1.get(ref_activity_col, 0) - mol2.get(ref_activity_col, 0)),
                    'structural_difference': get_structural_difference_keyword(mol1['SMILES'], mol2['SMILES']),
                    'is_stereoisomer': check_stereoisomers(mol1['SMILES'], mol2['SMILES']),
                    'mol1_properties': calculate_molecular_properties(mol1['mol']),
                    'mol2_properties': calculate_molecular_properties(mol2['mol']),
                    'same_scaffold': mol1.get('scaffold') == mol2.get('scaffold'),
                    'score': (abs(mol1.get(ref_activity_col, 0) - mol2.get(ref_activity_col, 0))) * (pair_info['similarity'] - sim_thresh) * (1 if mol1.get('scaffold') == mol2.get('scaffold') else 0.5)
                }
                process_and_display_pair(
                    idx=selected_idx, cliff_data=cliff_data_quant, sim_thresh=sim_thresh, 
                    activity_col=ref_activity_col, tab_key=f"quantitative_{tab_key}",
                    target_name=target_name, api_key=api_key, llm_provider=llm_provider
                )

def render_cliff_detection_ui(df, available_activity_cols, tab_key, target_name, api_key, llm_provider):
    st.info("êµ¬ì¡°ê°€ ìœ ì‚¬í•˜ì§€ë§Œ **ì„ íƒëœ í™œì„± ê°’ì˜ ì°¨ì´ê°€ í°** ìŒ(Activity Cliff)ì„ íƒìƒ‰í•©ë‹ˆë‹¤.")
    if not available_activity_cols:
        st.error("ì˜¤ë¥˜: ë¶„ì„ ê°€ëŠ¥í•œ í™œì„± ì»¬ëŸ¼(pKi/pIC50)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    selected_col = st.selectbox("ë¶„ì„ ê¸°ì¤€ ì»¬ëŸ¼ ì„ íƒ:", options=available_activity_cols, key=f'col_{tab_key}')
    with st.expander("í˜„ì¬ ë°ì´í„° í™œì„±ë„ ë¶„í¬ ë³´ê¸°"):
        plot_df_dist = df.copy()
        plot_df_dist[selected_col] = pd.to_numeric(plot_df_dist[selected_col], errors='coerce')
        plot_df_dist.dropna(subset=[selected_col], inplace=True)
        if not plot_df_dist.empty:
            st.metric(label=f"ë¶„ì„ì— ì‚¬ìš©ë  ìœ íš¨ ë°ì´í„° ê°œìˆ˜", value=f"{len(plot_df_dist)} ê°œ")
            display_cols = ['SMILES', 'Target', selected_col]
            st.dataframe(plot_df_dist[display_cols].head())
            fig_hist = px.histogram(plot_df_dist, x=selected_col, title=f'{selected_col} ê°’ ë¶„í¬', labels={selected_col: f'{selected_col} ê°’'})
            st.plotly_chart(fig_hist, use_container_width=True, key=f"histogram_{tab_key}")
        else:
            st.warning(f"'{selected_col}' ì»¬ëŸ¼ì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ì–´ ë¶„í¬ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    c1, c2 = st.columns(2)
    with c1: sim_thresh = st.slider("ìœ ì‚¬ë„ ì„ê³„ê°’", 0.5, 1.0, 0.8, 0.01, key=f'sim_{tab_key}')
    with c2: act_diff_thresh = st.slider(f"Î”{selected_col} ì„ê³„ê°’", 0.1, 5.0, 1.0, 0.1, key=f'act_{tab_key}')
    if st.button("í™œì„± ì ˆë²½ íƒì§€ ì‹¤í–‰", key=f'run_cliff_{tab_key}'):
        with st.spinner("í™œì„± ì ˆë²½ ë¶„ì„ ì¤‘..."):
            cliffs = find_activity_cliffs(df, sim_thresh, act_diff_thresh, selected_col)
            st.session_state[f'cliffs_{tab_key}'] = cliffs
            st.session_state[f'analyzed_col_{tab_key}'] = selected_col

    if f'cliffs_{tab_key}' in st.session_state:
        cliffs = st.session_state[f'cliffs_{tab_key}']
        analyzed_col = st.session_state.get(f'analyzed_col_{tab_key}', selected_col)
        st.success(f"ì´ {len(cliffs)}ê°œì˜ í™œì„± ì ˆë²½ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        if cliffs:
            plot_df_scatter = pd.DataFrame(cliffs)
            plot_df_scatter['pair_label'] = plot_df_scatter.apply(
                lambda row: f"{row['mol_1'].get('ID', 'N/A')} vs {row['mol_2'].get('ID', 'N/A')}", axis=1
            )
            st.markdown("#### Activity Cliff ë¶„í¬ ì‹œê°í™”")
            fig_scatter = px.scatter(
                plot_df_scatter,
                x='similarity',
                y='activity_diff', 
                title='Activity Cliff ë¶„í¬ (ìš°ì¸¡ ìƒë‹¨ì´ ê°€ì¥ ìœ ì˜ë¯¸í•œ ì˜ì—­)',
                labels={'similarity': 'êµ¬ì¡° ìœ ì‚¬ë„ (Tanimoto)', 'activity_diff': f'í™œì„±ë„ ì°¨ì´ (Î”{analyzed_col})'}, # <<< ì—¬ê¸°ë„ ìˆ˜ì •
                hover_data=['pair_label', 'score'],
                color='score',
                color_continuous_scale=px.colors.sequential.Viridis,
                size='activity_diff' # <<< ì—¬ê¸°ë„ ìˆ˜ì •
            )
            fig_scatter.add_shape(
                type="rect", xref="x", yref="y",
                x0=sim_thresh, y0=act_diff_thresh, x1=1.0, 
                y1=plot_df_scatter['activity_diff'].max() * 1.1, # <<< ì—¬ê¸°ë¥¼ ìˆ˜ì •
                line=dict(color="Red", width=2, dash="dash"),
                fillcolor="rgba(255,0,0,0.1)"
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
            st.markdown("---")
        if not cliffs:
            st.warning("í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” í™œì„± ì ˆë²½ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì„ê³„ê°’ì„ ì¡°ì ˆí•´ë³´ì„¸ìš”.")
        else:
            st.markdown("#### ìƒì„¸ ë¶„ì„ ëª©ë¡")
            pair_options = [
                f"{idx+1}. {c['mol_1'].get('ID', 'N/A')} vs {c['mol_2'].get('ID', 'N/A')} "
                f"(ìœ ì‚¬ë„: {c['similarity']:.2f}, í™œì„±ì°¨ì´: {c['activity_diff']:.2f})"
                for idx, c in enumerate(cliffs)
            ]
            selected_pair_str = st.selectbox("ë¶„ì„í•  ìŒì„ ì„ íƒí•˜ì„¸ìš”:", pair_options, key=f"pair_select_{tab_key}")
            if selected_pair_str:
                selected_idx = pair_options.index(selected_pair_str)
                cliff = cliffs[selected_idx]
                process_and_display_pair(
                    idx=selected_idx, cliff_data=cliff, sim_thresh=sim_thresh, 
                    activity_col=analyzed_col, tab_key=tab_key,
                    target_name=target_name, api_key=api_key, llm_provider=llm_provider
                )


# --- [ìˆ˜ì • ì‹œì‘] DB ì—°ë™ì„ ìœ„í•œ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ---
db_path = "/Users/lionkim/Downloads/project_archive/sar-project/patent_etl_pipeline/database/patent_data.db" 

@st.cache_data
def get_target_list(database_path):
    """DBì˜ targets í…Œì´ë¸”ì—ì„œ ì „ì²´ íƒ€ê²Ÿ ì´ë¦„ ëª©ë¡ë§Œ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not os.path.exists(database_path):
        st.sidebar.error(f"DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {database_path}")
        return []
    try:
        conn = sqlite3.connect(database_path, check_same_thread=False)
        # targets í…Œì´ë¸”ì—ì„œ target_nameë§Œ ì¡°íšŒ
        query = "SELECT target_name FROM targets ORDER BY target_name;"
        df = pd.read_sql_query(query, conn)
        return df['target_name'].tolist()
    except Exception as e:
        st.sidebar.error(f"DB íƒ€ê²Ÿ ëª©ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return []
    finally:
        if 'conn' in locals() and conn:
            conn.close()

@st.cache_data
def get_data_for_target(database_path, target_name):
    """ì‚¬ìš©ìê°€ ì„ íƒí•œ íŠ¹ì • íƒ€ê²Ÿì˜ ë°ì´í„°ë§Œ DBì—ì„œ JOINí•˜ì—¬ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not os.path.exists(database_path): return None
    try:
        conn = sqlite3.connect(database_path, check_same_thread=False)
        # ì œê³µí•´ì£¼ì‹  ì¿¼ë¦¬ì— WHERE ì ˆì„ ì¶”ê°€í•˜ì—¬ íŠ¹ì • íƒ€ê²Ÿ ë°ì´í„°ë§Œ ì„ íƒ
        query = """
        SELECT
            c.smiles AS "SMILES",
            t.target_name AS "Target",
            a.pic50 AS "pIC50",
            a.ic50 AS "IC50",
            a.activity_category AS "Activity",
            c.compound_id AS "ID"
        FROM activities a
        JOIN compounds c ON a.compound_id = c.compound_id
        JOIN targets t ON a.target_id = t.target_id
        WHERE t.target_name = ?;
        """
        # SQL Injection ê³µê²© ë°©ì§€ë¥¼ ìœ„í•´ íŒŒë¼ë¯¸í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì¿¼ë¦¬ ì‹¤í–‰
        df = pd.read_sql_query(query, conn, params=(target_name,))
        return df
    except Exception as e:
        st.error(f"'{target_name}' ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return None
    finally:
        if 'conn' in locals() and conn:
            conn.close()

@st.cache_data
def get_data_from_db(database_path):
    """SQLite ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
    if not os.path.exists(database_path):
        st.sidebar.error(f"DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {database_path}")
        return None
    try:
        conn = sqlite3.connect(database_path, check_same_thread=False)
        # ì›ë³¸ utils.pyì˜ load_dataê°€ ì²˜ë¦¬í•˜ëŠ” ì»¬ëŸ¼ë“¤ì„ ëª¨ë‘ ê°€ì ¸ì˜µë‹ˆë‹¤.
        # ì»¬ëŸ¼ëª…ì„ ì›ë³¸ load_data í•¨ìˆ˜ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ê³¼ ìœ ì‚¬í•˜ê²Œ ë§ì¶°ì¤ë‹ˆë‹¤.
        query = """
        SELECT
            c.smiles AS "SMILES",
            t.target_name AS "Target",
            a.pic50 AS "pIC50",
            a.ic50 AS "IC50",
            a.activity_category AS "Activity",
            c.compound_id AS "ID"
        FROM activities a
        JOIN compounds c ON a.compound_id = c.compound_id
        JOIN targets t ON a.target_id = t.target_id;
        """
        df = pd.read_sql_query(query, conn)
        return df
    except Exception as e:
        st.sidebar.error(f"DB ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return None
    finally:
        if 'conn' in locals() and conn:
            conn.close()
# --- [ìˆ˜ì • ë] ---


# --- Main App ---
def main():
    with st.sidebar:
        st.title("AI SAR ë¶„ì„ ì‹œìŠ¤í…œ")
        st.info("AI ê¸°ë°˜ êµ¬ì¡°-í™œì„± ê´€ê³„(SAR) ë¶„ì„ ë° ì˜ˆì¸¡ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.")
        
        st.header("ğŸ“ ë°ì´í„° ì„ íƒ")
        
        # 1ë‹¨ê³„: ì „ì²´ íƒ€ê²Ÿ ëª©ë¡ë§Œ ë¹ ë¥´ê²Œ ë¡œë“œí•˜ì—¬ Selectboxë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        target_list = get_target_list(db_path)
        selected_target = None
        
        if target_list:
            selected_target = st.selectbox('ë¶„ì„í•  íƒ€ê²Ÿ ì„ íƒ', target_list)
        else:
            st.warning("ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ íƒ€ê²Ÿ ëª©ë¡ì„ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        st.header("âš™ï¸ AI ëª¨ë¸ ì„¤ì •")
        # target_name_inputì€ ì´ì œ ê¸°ë³¸ê°’ ë˜ëŠ” ë³´ì¡° ìš©ë„ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        target_name_input = st.text_input("ë¶„ì„ ëŒ€ìƒ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ (ì°¸ê³ ìš©)", value=selected_target or "EGFR")
        llm_provider = st.selectbox("LLM ê³µê¸‰ì ì„ íƒ:", ("OpenAI", "Gemini"))
        api_key = st.text_input("API í‚¤ ì…ë ¥:", type="password", placeholder="OpenAI ë˜ëŠ” Gemini API í‚¤")

    st.header("ë¶„ì„ ê²°ê³¼ ëŒ€ì‹œë³´ë“œ")
    df, available_activity_cols = None, []
    
    # 2ë‹¨ê³„: ì‚¬ìš©ìê°€ íƒ€ê²Ÿì„ ì„ íƒí•œ ê²½ìš°ì—ë§Œ í•´ë‹¹ ë°ì´í„°ë¥¼ DBì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
    if selected_target:
        with st.spinner(f"'{selected_target}' ë°ì´í„° ë¡œë”© ì¤‘..."):
            # íŠ¹ì • íƒ€ê²Ÿì˜ ë°ì´í„°ë§Œ DBì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            df_from_db = get_data_for_target(db_path, selected_target)
        
        if df_from_db is not None:
            # 3ë‹¨ê³„: ë¡œë“œëœ ë°ì´í„°ë¥¼ í›„ì²˜ë¦¬ í•¨ìˆ˜(utils.pyì˜ load_data)ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
            df_processed, available_activity_cols = load_data(df_from_db)

            if df_processed is not None:
                # --- [ìˆ˜ì •ëœ ë¶€ë¶„ ì‹œì‘] ---
                # ì´ ë‹¨ê³„ì—ì„œ ë¯¸ë¦¬ ì¤‘ë³µì„ ì œê±°í•©ë‹ˆë‹¤.
                ref_col = available_activity_cols[0] if available_activity_cols else 'pIC50'
                if ref_col in df_processed.columns:
                    # 1. í™œì„±ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                    df_sorted = df_processed.sort_values(ref_col, ascending=False)
                    # 2. SMILES ê¸°ì¤€ ì¤‘ë³µ ì œê±° (ê°€ì¥ í™œì„±ë„ ë†’ì€ ë°ì´í„°ë§Œ ë‚¨ê¹€)
                    df = df_sorted.drop_duplicates(subset=['SMILES'], keep='first')
                else:
                    df = df_processed.drop_duplicates(subset=['SMILES'], keep='first')
                
                st.sidebar.success(f"ì´ {len(df_from_db)}ê°œ ë°ì´í„° ì¤‘ {len(df)}ê°œì˜ ê³ ìœ  í™”í•©ë¬¼ ë¡œë“œ ì™„ë£Œ!")
                # --- [ìˆ˜ì •ëœ ë¶€ë¶„ ë] ---
            
            # Activity ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°, pKi/pIC50 ê¸°ì¤€ìœ¼ë¡œ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
            if df is not None and 'Activity' not in df.columns and any(col in df.columns for col in ['pKi', 'pIC50']):
                ref_col = 'pKi' if 'pKi' in df.columns else 'pIC50'
                conditions = [
                    (df[ref_col] > 7.0),
                    (df[ref_col] > 5.7) & (df[ref_col] <= 7.0),
                    (df[ref_col] > 5.0) & (df[ref_col] <= 5.7),
                    (df[ref_col] <= 5.0) | (df[ref_col].isna())
                ]
                labels = ['Highly Active', 'Moderately Active', 'Weakly Active', 'Inactive']
                df['Activity'] = np.select(conditions, labels, default='Unclassified')
                st.info("Info: pKi/pIC50 ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ Activity ì»¬ëŸ¼ì„ ìƒˆë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

    # 4ë‹¨ê³„: ìµœì¢… ì²˜ë¦¬ëœ ë°ì´í„°(df)ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ë¶„ì„ íƒ­ë“¤ì„ ë Œë”ë§í•©ë‹ˆë‹¤.
    if df is not None:
        st.success(f"'{selected_target}'ì— ëŒ€í•œ {len(df)}ê°œì˜ í™”í•©ë¬¼ ë°ì´í„° ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ!")
        
        tabs_to_create = []
        if ONLINE_DISCUSSION_AVAILABLE: tabs_to_create.append("SAR ë¶„ì„ (í† ë¡  ì‹œìŠ¤í…œ ì ìš©)")
        tabs_to_create.append("SAR ë¶„ì„ (ê¸°ë³¸)")
        if PROMPT_SYSTEM_AVAILABLE: tabs_to_create.append("ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡ ")
        
        created_tabs = st.tabs(tabs_to_create)
        tab_map = {name: tab for name, tab in zip(tabs_to_create, created_tabs)}
        
        tab_advanced = tab_map.get("SAR ë¶„ì„ (í† ë¡  ì‹œìŠ¤í…œ ì ìš©)")
        tab_basic = tab_map.get("SAR ë¶„ì„ (ê¸°ë³¸)")
        tab_prompt = tab_map.get("ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡ ")

        # ë¶„ì„ í•¨ìˆ˜ì— ì „ë‹¬í•  íƒ€ê²Ÿ ì´ë¦„ì€ ì´ì œ ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒëœ ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        target_name_to_use = selected_target

        if tab_advanced:
            with tab_advanced:
                st.subheader("êµ¬ì¡°-í™œì„± ê´€ê³„ ë¶„ì„ (í† ë¡  ì‹œìŠ¤í…œ ì ìš©)")
                analysis_type_adv = st.radio("ë¶„ì„ ìœ í˜• ì„ íƒ:", ("í™œì„± ì ˆë²½ íƒì§€", "ì •ëŸ‰ ë¶„ì„"), horizontal=True, key="adv_type")
                st.markdown("---")
                if analysis_type_adv == "ì •ëŸ‰ ë¶„ì„":
                    render_quantitative_analysis_ui(df, available_activity_cols, 'advanced', target_name_to_use, api_key, llm_provider)
                else:
                    render_cliff_detection_ui(df, available_activity_cols, 'advanced', target_name_to_use, api_key, llm_provider)
        
        if tab_basic:
            with tab_basic:
                st.subheader("êµ¬ì¡°-í™œì„± ê´€ê³„ ë¶„ì„ (ê¸°ë³¸)")
                analysis_type_basic = st.radio("ë¶„ì„ ìœ í˜• ì„ íƒ:", ("í™œì„± ì ˆë²½ íƒì§€", "ì •ëŸ‰ ë¶„ì„"), horizontal=True, key="basic_type")
                st.markdown("---")
                if analysis_type_basic == "ì •ëŸ‰ ë¶„ì„":
                    render_quantitative_analysis_ui(df, available_activity_cols, 'basic', target_name_to_use, api_key, llm_provider)
                else:
                    render_cliff_detection_ui(df, available_activity_cols, 'basic', target_name_to_use, api_key, llm_provider)

        if tab_prompt:
            with tab_prompt:
                st.markdown("# ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  ì‹œìŠ¤í…œ")
                # (ì´í•˜ í”„ë¡¬í”„íŠ¸ í† ë¡  íƒ­ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼)
    else:
        st.info("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ ë¶„ì„í•  íƒ€ê²Ÿì„ ì„ íƒí•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()

