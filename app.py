import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.express as px
from rdkit import Chem
from rdkit.Chem import DataStructs, rdFingerprintGenerator
from rdkit.Chem.Scaffolds import MurckoScaffold
import json
from sqlalchemy.orm import Session
from patent_etl_pipeline.database import SessionLocal, Patent, Compound, Target, Activity, SAR_Analysis, AI_Hypothesis

from utils import (
    load_data,
    find_activity_cliffs,
    find_quantitative_pairs,
    generate_hypothesis_cliff,
    generate_hypothesis_quantitative,
    draw_highlighted_pair,
    check_stereoisomers,
    calculate_molecular_properties,
    get_structural_difference_keyword,
    save_results_to_db,
    get_analysis_history
)

# --- ì™¸ë¶€ ì‹œìŠ¤í…œ ì„í¬íŠ¸ ---
try:
    from online_discussion_system import run_online_discussion_system
    ONLINE_DISCUSSION_AVAILABLE = True
    print("âœ… Co-Scientist ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    ONLINE_DISCUSSION_AVAILABLE = False
    print(f"âŒ Co-Scientist ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

try:
    from llm_debate.debate.optimal_prompt_debate_manager import OptimalPromptDebateManager
    from streamlit_components.optimal_prompt_debate_interface import OptimalPromptDebateInterface
    PROMPT_SYSTEM_AVAILABLE = True
    print("âœ… ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    PROMPT_SYSTEM_AVAILABLE = False
    print(f"âŒ ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")

# --- í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="AI ê¸°ë°˜ SAR ë¶„ì„ ì‹œìŠ¤í…œ", page_icon="ğŸ§ª", layout="wide")


# --- ê³µí†µ ë¡œì§ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ ---
def process_and_display_pair(idx, cliff_data, sim_thresh, activity_col, tab_key, target_name, api_key, llm_provider, selected_patent):
    mol1 = pd.Series(cliff_data['mol_1'])
    mol2 = pd.Series(cliff_data['mol_2'])
    similarity = cliff_data['similarity']
    
    header = f"ìŒ #{idx+1} (ID: {mol1.get('ID', 'N/A')} vs {mol2.get('ID', 'N/A')}) | ìœ ì‚¬ë„: {similarity:.3f}"
    
    with st.expander(header, expanded=True):
        real_act_diff = cliff_data['activity_diff']
        structural_diff = cliff_data['structural_difference']
        is_stereoisomer = cliff_data['is_stereoisomer']
        mol1_props = cliff_data['mol1_properties']
        mol2_props = cliff_data['mol2_properties']
        
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Tanimoto ìœ ì‚¬ë„", f"{similarity:.3f}")
        c2.metric(f"Î”{activity_col}", f"{real_act_diff:.3f}")
        c3.metric("êµ¬ì¡°ì  ì°¨ì´", structural_diff)
        c4.metric("ì…ì²´ì´ì„±ì§ˆì²´", "ì˜ˆ" if is_stereoisomer else "ì•„ë‹ˆì˜¤")

        with st.container():
            sub_c1, sub_c2, sub_c3 = st.columns(3)
            with sub_c1:
                st.metric(f"{mol1.get('ID', 'N/A')} ë¶„ìëŸ‰", f"{mol1_props.get('molecular_weight', 0):.1f} Da")
                st.metric(f"{mol1.get('ID', 'N/A')} LogP", f"{mol1_props.get('logp', 0):.2f}")
            with sub_c2:
                st.metric(f"{mol2.get('ID', 'N/A')} ë¶„ìëŸ‰", f"{mol2_props.get('molecular_weight', 0):.1f} Da")
                st.metric(f"{mol2.get('ID', 'N/A')} LogP", f"{mol2_props.get('logp', 0):.2f}")
            with sub_c3:
                mw_diff = abs(mol1_props.get('molecular_weight', 0) - mol2_props.get('molecular_weight', 0))
                logp_diff = abs(mol1_props.get('logp', 0) - mol2_props.get('logp', 0))
                st.metric("ë¶„ìëŸ‰ ì°¨ì´", f"{mw_diff:.1f} Da")
                st.metric("LogP ì°¨ì´", f"{logp_diff:.2f}")
        st.markdown("---")

        svg1, svg2 = draw_highlighted_pair(mol1['SMILES'], mol2['SMILES'])
        c1, c2 = st.columns(2)
        with c1:
            st.markdown(f"**í™”í•©ë¬¼ 1: {mol1.get('ID', 'N/A')}**")
            metric_label_1 = f"{activity_col} ({mol1.get('Activity', 'N/A')})"
            metric_value_1 = f"{mol1.get(activity_col, 0):.3f}"
            st.metric(label=metric_label_1, value=metric_value_1)
            st.image(svg1, use_container_width=True)
        with c2:
            st.markdown(f"**í™”í•©ë¬¼ 2: {mol2.get('ID', 'N/A')}**")
            metric_label_2 = f"{activity_col} ({mol2.get('Activity', 'N/A')})"
            metric_value_2 = f"{mol2.get(activity_col, 0):.3f}"
            st.metric(label=metric_label_2, value=metric_value_2)
            st.image(svg2, use_container_width=True)
        
        st.markdown("---")

        if tab_key.endswith('basic'):
            if st.button("AI ê°€ì„¤ ìƒì„±", key=f"gen_hyp_{idx}_{tab_key}"):
                if not api_key: st.warning("ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("AI ê°€ì„¤ ìƒì„± ì¤‘..."):
                        if tab_key.startswith('quantitative'):
                            hypothesis, context = generate_hypothesis_quantitative(mol1, mol2, similarity, target_name, api_key, llm_provider)
                        else: 
                            hypothesis, context = generate_hypothesis_cliff(cliff_data, target_name, api_key, llm_provider, activity_col)
                        st.markdown(hypothesis)
                        if context:
                            with st.expander("ì°¸ê³  ë¬¸í—Œ ì •ë³´ (RAG)"): st.json(context)

        elif tab_key.endswith('advanced'):

         if st.button("ì˜¨ë¼ì¸ í† ë¡  ì‹œì‘ ë° ê²°ê³¼ ì €ì¥", key=f"disc_{idx}_{tab_key}"):
            if not api_key: 
                st.warning("ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            elif not ONLINE_DISCUSSION_AVAILABLE: 
                st.error("ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                with st.spinner("AI ì „ë¬¸ê°€ë“¤ì´ í† ë¡  í›„ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤..."):
                    # 1. ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ ì‹¤í–‰í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ë°›ê¸°
                    final_report = run_online_discussion_system(cliff_data, target_name, api_key, llm_provider)
                    
                    st.markdown("### ì „ë¬¸ê°€ í† ë¡  ìµœì¢… ë¦¬í¬íŠ¸")
                    st.json(final_report)

                    # 2. utilsì˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ DBì— ìµœì¢… ë¦¬í¬íŠ¸ ì €ì¥
                    # final_reportê°€ dict í˜•íƒœì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, json.dumpsë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
                    report_text = json.dumps(final_report, indent=2, ensure_ascii=False)
                    
                    saved_id = save_results_to_db(
                        patent_number=selected_patent,
                        cliff_data=cliff_data,
                        hypothesis_text=report_text, # ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì €ì¥
                        llm_provider="Expert Discussion System", # ì—ì´ì „íŠ¸ ì´ë¦„ ë³€ê²½
                        context_info=None # ë¦¬í¬íŠ¸ ìì²´ì— í¬í•¨ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                    )

                    if saved_id:
                        st.success(f"í† ë¡  ë¦¬í¬íŠ¸ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. (Analysis ID: {saved_id})")
                    else:
                        st.error("ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


# --- UI ë Œë”ë§ í•¨ìˆ˜  ---

def render_quantitative_analysis_ui(df, available_activity_cols, tab_key, target_name, api_key, llm_provider, selected_patent):
    st.info("êµ¬ì¡°ì ìœ¼ë¡œ ìœ ì‚¬í•˜ì§€ë§Œ **í™œì„± ë¶„ë¥˜(Activity)ê°€ ë‹¤ë¥¸** í™”í•©ë¬¼ ìŒì„ íƒìƒ‰í•©ë‹ˆë‹¤.")
    if 'Activity' not in df.columns or not available_activity_cols:
        st.error("ì˜¤ë¥˜: ë¶„ì„ì— í•„ìš”í•œ 'Activity' ë˜ëŠ” í™œì„± ì»¬ëŸ¼(pKi/pIC50)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    ref_activity_col = available_activity_cols[0]

    sim_thresh = st.slider("ìœ ì‚¬ë„ ì„ê³„ê°’", 0.5, 1.0, 0.8, 0.01, key=f'sim_quant_{tab_key}')
    
    if st.button("ì •ëŸ‰ ë¶„ì„ ì‹¤í–‰", key=f'run_quant_{tab_key}'):
        with st.spinner("ì •ëŸ‰ ë¶„ì„ ì¤‘..."):
            # --- [ìˆ˜ì •ëœ ë¶€ë¶„] ---
            # ë³µì¡í•œ ë¶„ì„ ë¡œì§ ëŒ€ì‹  utils.pyì˜ í•¨ìˆ˜ë¥¼ í•œ ì¤„ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.
            pairs, df_quant_processed = find_quantitative_pairs(df, sim_thresh, ref_activity_col)
            # --- [ìˆ˜ì •ëœ ë¶€ë¶„ ë] ---
            
            st.session_state[f'quant_pairs_{tab_key}'] = pairs
            st.session_state[f'quant_data_{tab_key}'] = df_quant_processed

    if f'quant_pairs_{tab_key}' in st.session_state:
        pairs = st.session_state[f'quant_pairs_{tab_key}']
        df_quant_valid = st.session_state[f'quant_data_{tab_key}']
        
        st.success(f"ì´ {len(pairs)}ê°œì˜ ìœ ì˜ë¯¸í•œ í™”í•©ë¬¼ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        if not pairs:
            st.warning("í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” í™”í•©ë¬¼ ìŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì„ê³„ê°’ì„ ì¡°ì ˆí•´ë³´ì„¸ìš”.")
        else:
            st.markdown("#### ìƒì„¸ ë¶„ì„ ëª©ë¡")
            pair_options = [
                f"{idx+1}. {df_quant_valid.iloc[p['mol1_index']].get('ID', 'N/A')} vs {df_quant_valid.iloc[p['mol2_index']].get('ID', 'N/A')} "
                f"(ìœ ì‚¬ë„: {p['similarity']:.2f}, ë¶„ë¥˜ì°¨ì´ ì ìˆ˜: {p.get('activity_category_diff', 0)})" 
                for idx, p in enumerate(pairs)
            ]
            selected_pair_str = st.selectbox("ë¶„ì„í•  ìŒì„ ì„ íƒí•˜ì„¸ìš”:", pair_options, key=f"pair_select_{tab_key}")
            if selected_pair_str:
                selected_idx = pair_options.index(selected_pair_str)
                pair_info = pairs[selected_idx]
                mol1 = df_quant_valid.iloc[pair_info['mol1_index']]
                mol2 = df_quant_valid.iloc[pair_info['mol2_index']]
                cliff_data_quant = {
                    'mol_1': mol1.to_dict(),
                    'mol_2': mol2.to_dict(),
                    'similarity': pair_info['similarity'],
                    'activity_diff': abs(mol1.get(ref_activity_col, 0) - mol2.get(ref_activity_col, 0)),
                    'structural_difference': get_structural_difference_keyword(mol1['SMILES'], mol2['SMILES']),
                    'is_stereoisomer': check_stereoisomers(mol1['SMILES'], mol2['SMILES']),
                    'mol1_properties': calculate_molecular_properties(mol1['mol']),
                    'mol2_properties': calculate_molecular_properties(mol2['mol']),
                    'same_scaffold': mol1.get('scaffold') == mol2.get('scaffold'),
                    'score': (abs(mol1.get(ref_activity_col, 0) - mol2.get(ref_activity_col, 0))) * (pair_info['similarity'] - sim_thresh) * (1 if mol1.get('scaffold') == mol2.get('scaffold') else 0.5)
                }
                process_and_display_pair(
                    idx=selected_idx, cliff_data=cliff_data_quant, sim_thresh=sim_thresh, 
                    activity_col=ref_activity_col, tab_key=f"quantitative_{tab_key}",
                    target_name=target_name, api_key=api_key, llm_provider=llm_provider, selected_patent=selected_patent
                )

def render_cliff_detection_ui(df, available_activity_cols, tab_key, target_name, api_key, llm_provider, selected_patent):
    st.info("êµ¬ì¡°ê°€ ìœ ì‚¬í•˜ì§€ë§Œ **ì„ íƒëœ í™œì„± ê°’ì˜ ì°¨ì´ê°€ í°** ìŒ(Activity Cliff)ì„ íƒìƒ‰í•©ë‹ˆë‹¤.")
    if not available_activity_cols:
        st.error("ì˜¤ë¥˜: ë¶„ì„ ê°€ëŠ¥í•œ í™œì„± ì»¬ëŸ¼(pKi/pIC50)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    selected_col = st.selectbox("ë¶„ì„ ê¸°ì¤€ ì»¬ëŸ¼ ì„ íƒ:", options=available_activity_cols, key=f'col_{tab_key}')
    with st.expander("í˜„ì¬ ë°ì´í„° í™œì„±ë„ ë¶„í¬ ë³´ê¸°"):
        plot_df_dist = df.copy()
        plot_df_dist[selected_col] = pd.to_numeric(plot_df_dist[selected_col], errors='coerce')
        plot_df_dist.dropna(subset=[selected_col], inplace=True)
        if not plot_df_dist.empty:
            st.metric(label=f"ë¶„ì„ì— ì‚¬ìš©ë  ìœ íš¨ ë°ì´í„° ê°œìˆ˜", value=f"{len(plot_df_dist)} ê°œ")
            display_cols = ['SMILES', 'Target', selected_col]
            st.dataframe(plot_df_dist[display_cols].head())
            fig_hist = px.histogram(plot_df_dist, x=selected_col, title=f'{selected_col} ê°’ ë¶„í¬', labels={selected_col: f'{selected_col} ê°’'})
            st.plotly_chart(fig_hist, use_container_width=True, key=f"histogram_{tab_key}")
        else:
            st.warning(f"'{selected_col}' ì»¬ëŸ¼ì— ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ì–´ ë¶„í¬ë¥¼ í‘œì‹œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    c1, c2 = st.columns(2)
    with c1: sim_thresh = st.slider("ìœ ì‚¬ë„ ì„ê³„ê°’", 0.5, 1.0, 0.8, 0.01, key=f'sim_{tab_key}')
    with c2: act_diff_thresh = st.slider(f"Î”{selected_col} ì„ê³„ê°’", 0.1, 5.0, 1.0, 0.1, key=f'act_{tab_key}')
    if st.button("í™œì„± ì ˆë²½ íƒì§€ ì‹¤í–‰", key=f'run_cliff_{tab_key}'):
        with st.spinner("í™œì„± ì ˆë²½ ë¶„ì„ ì¤‘..."):
            cliffs = find_activity_cliffs(df, sim_thresh, act_diff_thresh, selected_col)
            st.session_state[f'cliffs_{tab_key}'] = cliffs
            st.session_state[f'analyzed_col_{tab_key}'] = selected_col

    if f'cliffs_{tab_key}' in st.session_state:
        cliffs = st.session_state[f'cliffs_{tab_key}']
        analyzed_col = st.session_state.get(f'analyzed_col_{tab_key}', selected_col)
        st.success(f"ì´ {len(cliffs)}ê°œì˜ í™œì„± ì ˆë²½ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        if cliffs:
            plot_df_scatter = pd.DataFrame(cliffs)
            plot_df_scatter['pair_label'] = plot_df_scatter.apply(
                lambda row: f"{row['mol_1'].get('ID', 'N/A')} vs {row['mol_2'].get('ID', 'N/A')}", axis=1
            )
            st.markdown("#### Activity Cliff ë¶„í¬ ì‹œê°í™”")
            fig_scatter = px.scatter(
                plot_df_scatter,
                x='similarity',
                y='activity_diff', 
                title='Activity Cliff ë¶„í¬ (ìš°ì¸¡ ìƒë‹¨ì´ ê°€ì¥ ìœ ì˜ë¯¸í•œ ì˜ì—­)',
                labels={'similarity': 'êµ¬ì¡° ìœ ì‚¬ë„ (Tanimoto)', 'activity_diff': f'í™œì„±ë„ ì°¨ì´ (Î”{analyzed_col})'}, 
                hover_data=['pair_label', 'score'],
                color='score',
                color_continuous_scale=px.colors.sequential.Viridis,
                size='activity_diff' 
            )
            fig_scatter.add_shape(
                type="rect", xref="x", yref="y",
                x0=sim_thresh, y0=act_diff_thresh, x1=1.0, 
                y1=plot_df_scatter['activity_diff'].max() * 1.1, # <<< ì—¬ê¸°ë¥¼ ìˆ˜ì •
                line=dict(color="Red", width=2, dash="dash"),
                fillcolor="rgba(255,0,0,0.1)"
            )
            st.plotly_chart(fig_scatter, use_container_width=True)
            st.markdown("---")
        if not cliffs:
            st.warning("í˜„ì¬ ì¡°ê±´ì— ë§ëŠ” í™œì„± ì ˆë²½ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì„ê³„ê°’ì„ ì¡°ì ˆí•´ë³´ì„¸ìš”.")
        else:
            st.markdown("#### ìƒì„¸ ë¶„ì„ ëª©ë¡")
            pair_options = [
                f"{idx+1}. {c['mol_1'].get('ID', 'N/A')} vs {c['mol_2'].get('ID', 'N/A')} "
                f"(ìœ ì‚¬ë„: {c['similarity']:.2f}, í™œì„±ì°¨ì´: {c['activity_diff']:.2f})"
                for idx, c in enumerate(cliffs)
            ]
            selected_pair_str = st.selectbox("ë¶„ì„í•  ìŒì„ ì„ íƒí•˜ì„¸ìš”:", pair_options, key=f"pair_select_{tab_key}")
            if selected_pair_str:
                selected_idx = pair_options.index(selected_pair_str)
                cliff = cliffs[selected_idx]
                process_and_display_pair(
                    idx=selected_idx, cliff_data=cliff, sim_thresh=sim_thresh, 
                    activity_col=analyzed_col, tab_key=tab_key,
                    target_name=target_name, api_key=api_key, llm_provider=llm_provider, selected_patent=selected_patent
                )


# --- DB ì—°ë™ì„ ìœ„í•œ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ---
db_path = "patent_etl_pipeline/database/patent_data.db" 

@st.cache_data
def get_patent_list():
    """DBì—ì„œ ì „ì²´ íŠ¹í—ˆ ë²ˆí˜¸ ëª©ë¡ë§Œ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    db: Session = SessionLocal()
    try:
        patents = db.query(Patent.patent_number).order_by(Patent.patent_number.desc()).all()
        return [p[0] for p in patents] # íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¼ë°˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    except Exception as e:
        st.sidebar.error(f"DB íŠ¹í—ˆ ëª©ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return []
    finally:
        db.close()

@st.cache_data
def get_targets_for_patent(patent_number):
    """ì…ë ¥ëœ íŠ¹í—ˆ ë²ˆí˜¸ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  íƒ€ê²Ÿì˜ ì´ë¦„ì„ DBì—ì„œ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not patent_number: return []
    db: Session = SessionLocal()
    try:
        targets = db.query(Target.target_name)\
                    .join(Activity, Target.target_id == Activity.target_id)\
                    .join(Patent, Activity.patent_id == Patent.patent_id)\
                    .filter(Patent.patent_number == patent_number)\
                    .distinct().order_by(Target.target_name).all()
        return [t[0] for t in targets]
    except Exception as e:
        st.sidebar.error(f"íŠ¹í—ˆ '{patent_number}'ì˜ íƒ€ê²Ÿ ëª©ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return []
    finally:
        db.close()

@st.cache_data
def get_data_for_patent_and_target(patent_number, target_name):
    """íŠ¹ì • íŠ¹í—ˆì™€ íŠ¹ì • íƒ€ê²Ÿì— ëŒ€í•œ ë°ì´í„°ë§Œ DBì—ì„œ JOINí•˜ì—¬ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not all([patent_number, target_name]): return None
    db: Session = SessionLocal()
    try:
        # SQLAlchemyì˜ read_sql_queryë¥¼ ì‚¬ìš©í•˜ì—¬ DataFrameìœ¼ë¡œ ì§ì ‘ ë³€í™˜
        query = db.query(
                    Compound.smiles.label("SMILES"),
                    Compound.compound_id.label("ID"),
                    Target.target_name.label("Target"),
                    Patent.patent_number.label("Patent"),
                    Activity.ic50.label("IC50"),
                    Activity.pic50.label("pIC50"),
                    Activity.activity_category.label("Activity")
                ).join(Activity, Compound.compound_id == Activity.compound_id)\
                 .join(Target, Activity.target_id == Target.target_id)\
                 .join(Patent, Activity.patent_id == Patent.patent_id)\
                 .filter(Patent.patent_number == patent_number, Target.target_name == target_name).statement
        df = pd.read_sql_query(query, db.bind)
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return None
    finally:
        db.close()

# --- Main App ---
def main():
    with st.sidebar:
        st.title("AI SAR ë¶„ì„ ì‹œìŠ¤í…œ")
        st.info("AI ê¸°ë°˜ êµ¬ì¡°-í™œì„± ê´€ê³„(SAR) ë¶„ì„ ë° ì˜ˆì¸¡ ì†”ë£¨ì…˜ì…ë‹ˆë‹¤.")    
        st.header("ğŸ“ ë°ì´í„° ì„ íƒ")
        
        # 1. íŠ¹í—ˆ ë²ˆí˜¸ ì…ë ¥ (DBì— ìˆëŠ” ëª©ë¡ì—ì„œ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥)
        patent_list = get_patent_list()
        selected_patent = st.selectbox("1. ë¶„ì„í•  íŠ¹í—ˆ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:", options=[""] + patent_list)
        
        # 2. ì„ íƒëœ íŠ¹í—ˆì— í¬í•¨ëœ íƒ€ê²Ÿ ëª©ë¡ í‘œì‹œ
        selected_target = None
        if selected_patent:
            target_list = get_targets_for_patent(selected_patent)
            if target_list:
                selected_target = st.selectbox("2. ë¶„ì„í•  íƒ€ê²Ÿì„ ì„ íƒí•˜ì„¸ìš”:", options=[""] + target_list)
            else:
                st.warning(f"'{selected_patent}' íŠ¹í—ˆì— ëŒ€í•œ íƒ€ê²Ÿ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.header("âš™ï¸ AI ëª¨ë¸ ì„¤ì •")
        # target_name_inputì€ ì´ì œ ê¸°ë³¸ê°’ ë˜ëŠ” ë³´ì¡° ìš©ë„ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.
        target_name_input = st.text_input("ë¶„ì„ ëŒ€ìƒ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ (ì°¸ê³ ìš©)", value=selected_target or "EGFR")
        llm_provider = st.selectbox("LLM ê³µê¸‰ì ì„ íƒ:", ("OpenAI", "Gemini"))
        api_key = st.text_input("API í‚¤ ì…ë ¥:", type="password", placeholder="OpenAI ë˜ëŠ” Gemini API í‚¤")

    # --- íƒ­ êµ¬ì¡° ì •ì˜ ---
    tab_titles = ["ì‹¤ì‹œê°„ ë¶„ì„", "ë¶„ì„ ì´ë ¥ ì¡°íšŒ"]
    
    # ì™¸ë¶€ ì‹œìŠ¤í…œ ê°€ìš©ì„±ì— ë”°ë¼ ë™ì ìœ¼ë¡œ íƒ­ ì¶”ê°€ (ê¸°ì¡´ ë¡œì§ í™œìš©)
    # if ONLINE_DISCUSSION_AVAILABLE: tab_titles.insert(1, "SAR ë¶„ì„ (í† ë¡  ì‹œìŠ¤í…œ ì ìš©)") # í† ë¡  ì‹œìŠ¤í…œì„ ë³„ë„ íƒ­ìœ¼ë¡œ ë¶„ë¦¬í•  ê²½ìš°
    if PROMPT_SYSTEM_AVAILABLE: tab_titles.append("ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡ ")

    created_tabs = st.tabs(tab_titles)
    tab_map = {name: tab for name, tab in zip(tab_titles, created_tabs)}

    # --- íƒ­ 1: ì‹¤ì‹œê°„ ë¶„ì„ ---
    with tab_map["ì‹¤ì‹œê°„ ë¶„ì„"]:
        st.header("ì‹¤ì‹œê°„ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
        df, available_activity_cols = None, []

        # íŠ¹í—ˆì™€ íƒ€ê²Ÿì´ ëª¨ë‘ ì„ íƒë˜ì—ˆì„ ë•Œë§Œ ë°ì´í„° ë¡œë“œ ë° ì²˜ë¦¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.
        if selected_patent and selected_target:
            with st.spinner(f"íŠ¹í—ˆ '{selected_patent}'ì˜ '{selected_target}' ë°ì´í„° ë¡œë”© ì¤‘..."):
                # 1. íŠ¹í—ˆì™€ íƒ€ê²Ÿì— ë§ëŠ” ë°ì´í„°ë¥¼ DBì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                df_from_db = get_data_for_patent_and_target(selected_patent, selected_target)

            if df_from_db is not None:
                # 2. ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ utils.pyì˜ load_data í•¨ìˆ˜ë¡œ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤.
                df_processed, available_activity_cols = load_data(df_from_db)

                if df_processed is not None:
                    # 3. ë°ì´í„° ë¡œë“œ ì§í›„, ë¶„ì„ ì „ì— ì¤‘ë³µ í™”í•©ë¬¼ì„ ì œê±°í•©ë‹ˆë‹¤.
                    ref_col = available_activity_cols[0] if available_activity_cols else 'pIC50'
                    if ref_col in df_processed.columns:
                        # í™œì„±ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                        df_sorted = df_processed.sort_values(ref_col, ascending=False)
                        # SMILES ê¸°ì¤€ ì¤‘ë³µ ì œê±° (ê°€ì¥ í™œì„±ë„ ë†’ì€ ë°ì´í„°ë§Œ ë‚¨ê¹€)
                        df = df_sorted.drop_duplicates(subset=['SMILES'], keep='first')
                    else:
                        # í™œì„± ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš°, ê·¸ëƒ¥ SMILES ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
                        df = df_processed.drop_duplicates(subset=['SMILES'], keep='first')

                    st.sidebar.success(f"ì´ {len(df_from_db)}ê°œ í–‰ ì¤‘ {len(df)}ê°œì˜ ê³ ìœ  í™”í•©ë¬¼ ë¡œë“œ ì™„ë£Œ!")

                    # 4. Activity ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°, pKi/pIC50 ê¸°ì¤€ìœ¼ë¡œ ìë™ ìƒì„±í•©ë‹ˆë‹¤.
                    if 'Activity' not in df.columns and any(col in df.columns for col in ['pKi', 'pIC50']):
                        ref_col_act = 'pKi' if 'pKi' in df.columns else 'pIC50'
                        conditions = [
                            (df[ref_col_act] > 7.0),
                            (df[ref_col_act] > 5.7) & (df[ref_col_act] <= 7.0),
                            (df[ref_col_act] > 5.0) & (df[ref_col_act] <= 5.7),
                            (df[ref_col_act] <= 5.0) | (df[ref_col_act].isna())
                        ]
                        labels = ['Highly Active', 'Moderately Active', 'Weakly Active', 'Inactive']
                        df['Activity'] = np.select(conditions, labels, default='Unclassified')
                        st.info("Info: pKi/pIC50 ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ Activity ì»¬ëŸ¼ì„ ìƒˆë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

        # ìµœì¢… ì²˜ë¦¬ëœ ë°ì´í„°(df)ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ë¶„ì„ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
        if df is not None:
            st.success(f"'{selected_target}'ì— ëŒ€í•œ {len(df)}ê°œì˜ í™”í•©ë¬¼ ë°ì´í„° ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ!")

            # 'ì‹¤ì‹œê°„ ë¶„ì„' íƒ­ ë‚´ë¶€ì— ì„¸ë¶€ ë¶„ì„ íƒ­ë“¤ì„ ìƒì„±í•©ë‹ˆë‹¤.
            tabs_to_create_inner = []
            if ONLINE_DISCUSSION_AVAILABLE: tabs_to_create_inner.append("SAR ë¶„ì„ (í† ë¡  ì‹œìŠ¤í…œ ì ìš©)")
            tabs_to_create_inner.append("SAR ë¶„ì„ (ê¸°ë³¸)")

            created_tabs_inner = st.tabs(tabs_to_create_inner)
            tab_map_inner = {name: tab for name, tab in zip(tabs_to_create_inner, created_tabs_inner)}

            tab_advanced = tab_map_inner.get("SAR ë¶„ì„ (í† ë¡  ì‹œìŠ¤í…œ ì ìš©)")
            tab_basic = tab_map_inner.get("SAR ë¶„ì„ (ê¸°ë³¸)")

            # ë¶„ì„ í•¨ìˆ˜ì— ì „ë‹¬í•  íƒ€ê²Ÿ ì´ë¦„ì€ ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒëœ ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            target_name_to_use = selected_target

            if tab_advanced:
                with tab_advanced:
                    st.subheader("êµ¬ì¡°-í™œì„± ê´€ê³„ ë¶„ì„ (í† ë¡  ì‹œìŠ¤í…œ ì ìš©)")
                    analysis_type_adv = st.radio("ë¶„ì„ ìœ í˜• ì„ íƒ:", ("í™œì„± ì ˆë²½ íƒì§€", "ì •ëŸ‰ ë¶„ì„"), horizontal=True, key="adv_type")
                    st.markdown("---")
                    if analysis_type_adv == "ì •ëŸ‰ ë¶„ì„":
                        render_quantitative_analysis_ui(df, available_activity_cols, 'advanced', target_name_to_use, api_key, llm_provider, selected_patent)
                    else:
                        render_cliff_detection_ui(df, available_activity_cols, 'advanced', target_name_to_use, api_key, llm_provider, selected_patent)

            if tab_basic:
                with tab_basic:
                    st.subheader("êµ¬ì¡°-í™œì„± ê´€ê³„ ë¶„ì„ (ê¸°ë³¸)")
                    analysis_type_basic = st.radio("ë¶„ì„ ìœ í˜• ì„ íƒ:", ("í™œì„± ì ˆë²½ íƒì§€", "ì •ëŸ‰ ë¶„ì„"), horizontal=True, key="basic_type")
                    st.markdown("---")
                    if analysis_type_basic == "ì •ëŸ‰ ë¶„ì„":
                        render_quantitative_analysis_ui(df, available_activity_cols, 'basic', target_name_to_use, api_key, llm_provider, selected_patent)
                    else:
                        render_cliff_detection_ui(df, available_activity_cols, 'basic', target_name_to_use, api_key, llm_provider, selected_patent)
        else:
            st.info("ë¶„ì„ì„ ì‹œì‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ íŠ¹í—ˆì™€ íƒ€ê²Ÿì„ ëª¨ë‘ ì„ íƒí•˜ì„¸ìš”.")

    # --- íƒ­ 2: ë¶„ì„ ì´ë ¥ ì¡°íšŒ ---
    with tab_map["ë¶„ì„ ì´ë ¥ ì¡°íšŒ"]:
        st.header("ë¶„ì„ ì´ë ¥ ì¡°íšŒ")

        with st.spinner("ê³¼ê±° ë¶„ì„ ì´ë ¥ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            history_df = get_analysis_history()

        if history_df.empty:
            st.info("ì €ì¥ëœ ë¶„ì„ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. 'ì‹¤ì‹œê°„ ë¶„ì„' íƒ­ì—ì„œ ë¶„ì„ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ì¥í•´ì£¼ì„¸ìš”.")
        else:
            st.info(f"ì´ {len(history_df)}ê°œì˜ ë¶„ì„ ì´ë ¥ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            search_id = st.text_input("ê²€ìƒ‰í•  í™”í•©ë¬¼ ID (compound_id_1 ë˜ëŠ” compound_id_2):")
            
            display_df = history_df
            if search_id:
                try:
                    search_id_int = int(search_id)
                    display_df = history_df[
                        (history_df['compound_id_1'] == search_id_int) | 
                        (history_df['compound_id_2'] == search_id_int)
                    ]
                except ValueError:
                    st.warning("IDëŠ” ìˆ«ìë¡œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

            st.dataframe(display_df)

            st.markdown("---")
            st.subheader("ìƒì„¸ ì •ë³´ ë³´ê¸°")
            
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ê²€ìƒ‰ ê²°ê³¼ ë‚´ì—ì„œ, ì—†ìœ¼ë©´ ì „ì²´ ì´ë ¥ ë‚´ì—ì„œ ì„ íƒ
            detail_options = [""] + display_df['analysis_id'].tolist()
            selected_analysis_id = st.selectbox(
                "ìƒì„¸íˆ ë³¼ ë¶„ì„ IDë¥¼ ì„ íƒí•˜ì„¸ìš”:", 
                options=detail_options
            )

            if selected_analysis_id:
                detail_data = history_df[history_df['analysis_id'] == selected_analysis_id].iloc[0]
                
                st.json({
                    "ë¶„ì„ ID": detail_data['analysis_id'],
                    "ë¶„ì„ ì‹œê°„": detail_data['analysis_timestamp'],
                    "ë¶„ì„ ìŒ": f"ID {detail_data['compound_id_1']} vs ID {detail_data['compound_id_2']}",
                    "ìœ ì‚¬ë„": f"{detail_data['similarity']:.3f}" if pd.notna(detail_data['similarity']) else "N/A",
                    "í™œì„± ì°¨ì´": f"{detail_data['activity_difference']:.3f}" if pd.notna(detail_data['activity_difference']) else "N/A",
                    "ì ìˆ˜": f"{detail_data['score']:.2f}" if pd.notna(detail_data['score']) else "N/A",
                    "ë¶„ì„ ì—ì´ì „íŠ¸": detail_data['agent_name']
                })

                st.markdown("##### AI ìƒì„± ê°€ì„¤/ë¦¬í¬íŠ¸")
                try:
                    report_json = json.loads(detail_data['hypothesis_text'])
                    st.json(report_json)
                except (json.JSONDecodeError, TypeError):
                    st.info(detail_data['hypothesis_text'] or "ì €ì¥ëœ ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

