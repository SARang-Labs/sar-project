import streamlit as st
import pandas as pd
import numpy as np
import os
import io
import plotly.express as px
import json
from sqlalchemy.orm import Session
from patent_etl_pipeline.database import (
    SessionLocal, Patent, Compound, Target, Activity,
    DATABASE_PATH, init_db
)
from patent_etl_pipeline.run_etl import run_etl

from utils import (
    load_data,
    find_quantitative_pairs,
    generate_hypothesis_quantitative,
    draw_highlighted_pair,
    check_stereoisomers,
    calculate_molecular_properties,
    get_structural_difference_keyword,
    save_results_to_db,
    get_analysis_history
)

# --- ì™¸ë¶€ ì‹œìŠ¤í…œ ìž„í¬íŠ¸ ---
try:
    from online_discussion_system import run_online_discussion_system
    ONLINE_DISCUSSION_AVAILABLE = True
    print("âœ… ì‹œìŠ¤í…œ ë¡œë“œ ì„±ê³µ")
except ImportError as e:
    ONLINE_DISCUSSION_AVAILABLE = False
    print(f"âŒ ì‹œìŠ¤í…œ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")


# --- íŽ˜ì´ì§€ ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="AI ê¸°ë°˜ SAR ë¶„ì„ ì‹œìŠ¤í…œ", page_icon="ðŸ§ª", layout="wide")


# --- ê³µí†µ ë¡œì§ ì²˜ë¦¬ í—¬í¼ í•¨ìˆ˜ ---
def process_and_display_pair(idx, cliff_data, activity_col, tab_key, target_name, api_key, llm_provider, selected_patent, cell_line=None):
    mol1 = pd.Series(cliff_data['mol_1'])
    mol2 = pd.Series(cliff_data['mol_2'])
    similarity = cliff_data['similarity']
    
    header = f"ìŒ #{idx+1} (ID: {mol1.get('ID', 'N/A')} vs {mol2.get('ID', 'N/A')}) | ìœ ì‚¬ë„: {similarity:.3f}"
    
    with st.expander(header, expanded=True):
        real_act_diff = cliff_data['activity_difference']
        structural_diff = cliff_data['structural_difference']
        is_stereoisomer = cliff_data['is_stereoisomer']
        mol1_props = cliff_data['mol1_properties']
        mol2_props = cliff_data['mol2_properties']
        
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("Tanimoto ìœ ì‚¬ë„", f"{similarity:.3f}")
        c2.metric(f"Î”{activity_col}", f"{real_act_diff:.3f}")
        c3.metric("êµ¬ì¡°ì  ì°¨ì´", structural_diff)
        c4.metric("ìž…ì²´ì´ì„±ì§ˆì²´", "ì˜ˆ" if is_stereoisomer else "ì•„ë‹ˆì˜¤")

        with st.container():
            sub_c1, sub_c2, sub_c3 = st.columns(3)
            with sub_c1:
                st.metric(f"{mol1.get('ID', 'N/A')} ë¶„ìžëŸ‰", f"{mol1_props.get('molecular_weight', 0):.1f} Da")
                st.metric(f"{mol1.get('ID', 'N/A')} LogP", f"{mol1_props.get('logp', 0):.2f}")
            with sub_c2:
                st.metric(f"{mol2.get('ID', 'N/A')} ë¶„ìžëŸ‰", f"{mol2_props.get('molecular_weight', 0):.1f} Da")
                st.metric(f"{mol2.get('ID', 'N/A')} LogP", f"{mol2_props.get('logp', 0):.2f}")
            with sub_c3:
                mw_diff = abs(mol1_props.get('molecular_weight', 0) - mol2_props.get('molecular_weight', 0))
                logp_diff = abs(mol1_props.get('logp', 0) - mol2_props.get('logp', 0))
                st.metric("ë¶„ìžëŸ‰ ì°¨ì´", f"{mw_diff:.1f} Da")
                st.metric("LogP ì°¨ì´", f"{logp_diff:.2f}")
        st.markdown("---")

        svg1, svg2 = draw_highlighted_pair(mol1['SMILES'], mol2['SMILES'])
        c1, c2 = st.columns(2)
        with c1:
            st.markdown(f"**í™”í•©ë¬¼ 1: {mol1.get('ID', 'N/A')}**")
            metric_label_1 = f"{activity_col} ({mol1.get('Activity', 'N/A')})"
            metric_value_1 = f"{mol1.get(activity_col, 0):.3f}"
            st.metric(label=metric_label_1, value=metric_value_1)
            st.image(svg1, use_container_width=True)
        with c2:
            st.markdown(f"**í™”í•©ë¬¼ 2: {mol2.get('ID', 'N/A')}**")
            metric_label_2 = f"{activity_col} ({mol2.get('Activity', 'N/A')})"
            metric_value_2 = f"{mol2.get(activity_col, 0):.3f}"
            st.metric(label=metric_label_2, value=metric_value_2)
            st.image(svg2, use_container_width=True)
        
        st.markdown("---")

        if tab_key.endswith('basic'):
            if st.button("AI ê°€ì„¤ ìƒì„±", key=f"gen_hyp_{idx}_{tab_key}"):
                if not api_key: st.warning("ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
                else:
                    with st.spinner("AI ê°€ì„¤ ìƒì„± ì¤‘..."):
                        hypothesis, context = generate_hypothesis_quantitative(mol1, mol2, similarity, target_name, api_key, llm_provider)
                        st.markdown(hypothesis)
                        if context:
                            with st.expander("ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼"): st.json(context)

        elif tab_key.endswith('advanced'):

         if st.button("ë¶„ì„ ì‹œìž‘ ë° ê²°ê³¼ ì €ìž¥", key=f"disc_{idx}_{tab_key}"):
            if not api_key: 
                st.warning("ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
            elif not ONLINE_DISCUSSION_AVAILABLE: 
                st.error("ì˜¨ë¼ì¸ ë‹¤ê°ë„ ë¶„ì„ ì‹œìŠ¤í…œ ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                with st.spinner("AI ì „ë¬¸ê°€ë“¤ì´ ë‹¤ê°ë„ ë¶„ì„ í›„ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìž‘ì„±í•©ë‹ˆë‹¤..."):
                    # 1. ì˜¨ë¼ì¸ ë‹¤ê°ë„ ë¶„ì„ ì‹œìŠ¤í…œ ì‹¤í–‰í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ë°›ê¸°
                    # target_name: PDB ID (ë„í‚¹ìš©), cell_line: ì„¸í¬ì£¼ (ì‹¤í—˜ì¡°ê±´ìš©)
                    final_report = run_online_discussion_system(cliff_data, target_name, api_key, llm_provider, cell_line)
                    
                    # ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ ìžˆëŠ” ê²½ìš° ë³„ë„ í‘œì‹œ
                    if isinstance(final_report, dict) and 'domain_hypotheses' in final_report:
                        for hypothesis in final_report['domain_hypotheses']:
                            if hypothesis.get('agent_name') == 'ìƒì²´ë¶„ìž ìƒí˜¸ìž‘ìš© ì „ë¬¸ê°€' and 'docking_analysis' in hypothesis:
                                with st.expander("ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼", expanded=False):
                                    try:
                                        from online_discussion_system import display_docking_results
                                        display_docking_results(hypothesis['docking_analysis'], hypothesis['agent_name'])
                                    except ImportError:
                                        st.write("ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                                    
                                    with st.expander("ìƒì„¸ ë°ì´í„° (JSON)", expanded=False):
                                        st.json(hypothesis['docking_analysis'])
                                break
                    
                    # JSON ìƒì„¸ ë¶„ì„ì„ í† ê¸€ë¡œ í‘œì‹œ
                    with st.expander("ë¦¬í¬íŠ¸ ìƒì„¸ ê²°ê³¼ (JSON)", expanded=False):
                        st.json(final_report)

                    # 2. utilsì˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•˜ì—¬ DBì— ìµœì¢… ë¦¬í¬íŠ¸ ì €ìž¥
                    # final_reportê°€ dict í˜•íƒœì¼ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ, json.dumpsë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
                    report_text = json.dumps(final_report, indent=2, ensure_ascii=False)
                    
                    saved_id = save_results_to_db(
                        patent_number=selected_patent,
                        cliff_data=cliff_data,
                        hypothesis_text=report_text, # ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì €ìž¥
                        llm_provider="Expert Discussion System", # ì—ì´ì „íŠ¸ ì´ë¦„ ë³€ê²½
                        context_info=None # ë¦¬í¬íŠ¸ ìžì²´ì— í¬í•¨ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                    )

                    if saved_id:
                        st.success(f"ë¶„ì„ ë¦¬í¬íŠ¸ê°€ ë°ì´í„°ë² ì´ìŠ¤ì— ì„±ê³µì ìœ¼ë¡œ ì €ìž¥ë˜ì—ˆìŠµë‹ˆë‹¤. (Analysis ID: {saved_id})")
                    else:
                        st.error("ë°ì´í„°ë² ì´ìŠ¤ ì €ìž¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")


# --- UI ë Œë”ë§ í•¨ìˆ˜  ---

def render_quantitative_analysis_ui(df, available_activity_cols, tab_key, target_name, api_key, llm_provider, selected_patent, cell_line=None):
    st.info("êµ¬ì¡°ì ìœ¼ë¡œ ìœ ì‚¬í•˜ì§€ë§Œ **í™œì„± ë¶„ë¥˜(Activity)ê°€ ë‹¤ë¥¸** í™”í•©ë¬¼ ìŒì„ íƒìƒ‰í•©ë‹ˆë‹¤.")
    if 'Activity' not in df.columns or not available_activity_cols:
        st.error("ì˜¤ë¥˜: ë¶„ì„ì— í•„ìš”í•œ 'Activity' ë˜ëŠ” í™œì„± ì»¬ëŸ¼(pIC50/pKi)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    ref_activity_col = available_activity_cols[0]

    sim_thresh = st.slider("ìœ ì‚¬ë„ ìž„ê³„ê°’", 0.5, 1.0, 0.8, 0.01, key=f'sim_quant_{tab_key}')
    
    if st.button("ì •ëŸ‰ ë¶„ì„ ì‹¤í–‰", key=f'run_quant_{tab_key}'):
        with st.spinner("ì •ëŸ‰ ë¶„ì„ ì¤‘..."):
            # --- [ìˆ˜ì •ëœ ë¶€ë¶„] ---
            # ë³µìž¡í•œ ë¶„ì„ ë¡œì§ ëŒ€ì‹  utils.pyì˜ í•¨ìˆ˜ë¥¼ í•œ ì¤„ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤.
            pairs, df_quant_processed = find_quantitative_pairs(df, sim_thresh, ref_activity_col)
            # --- [ìˆ˜ì •ëœ ë¶€ë¶„ ë] ---
            
            st.session_state[f'quant_pairs_{tab_key}'] = pairs
            st.session_state[f'quant_data_{tab_key}'] = df_quant_processed

    if f'quant_pairs_{tab_key}' in st.session_state:
        pairs = st.session_state[f'quant_pairs_{tab_key}']
        df_quant_valid = st.session_state[f'quant_data_{tab_key}']
        
        st.success(f"ì´ {len(pairs)}ê°œì˜ ìœ ì˜ë¯¸í•œ í™”í•©ë¬¼ ìŒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        if not pairs:
            st.warning("í˜„ìž¬ ì¡°ê±´ì— ë§žëŠ” í™”í•©ë¬¼ ìŒì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìž„ê³„ê°’ì„ ì¡°ì ˆí•´ë³´ì„¸ìš”.")
        else:
            # Activity Cliff ë¶„í¬ ì‹œê°í™” ì¶”ê°€
            quantitative_plot_data = []
            for p in pairs:
                mol1 = df_quant_valid.iloc[p['mol1_index']]
                mol2 = df_quant_valid.iloc[p['mol2_index']]
                quantitative_plot_data.append({
                    'similarity': p['similarity'],
                    'activity_difference': abs(mol1.get(ref_activity_col, 0) - mol2.get(ref_activity_col, 0)),
                    'pair_label': f"{mol1.get('ID', 'N/A')} vs {mol2.get('ID', 'N/A')}",
                    'score': p.get('activity_category_diff', 0)
                })
            
            if quantitative_plot_data:
                plot_df_quant = pd.DataFrame(quantitative_plot_data)
                st.markdown("#### Activity Cliff ë¶„í¬ ì‹œê°í™”")
                fig_quant_scatter = px.scatter(
                    plot_df_quant,
                    x='similarity',
                    y='activity_difference', 
                    title='Activity Cliff ë¶„í¬ (ìš°ì¸¡ ìƒë‹¨ì´ ê°€ìž¥ ìœ ì˜ë¯¸í•œ ì˜ì—­)',
                    labels={'similarity': 'êµ¬ì¡° ìœ ì‚¬ë„ (Tanimoto)', 'activity_difference': f'í™œì„±ë„ ì°¨ì´ (Î”{ref_activity_col})'}, 
                    hover_data=['pair_label', 'score'],
                    color='score',
                    color_continuous_scale=px.colors.sequential.Viridis,
                    size='activity_difference' 
                )
                fig_quant_scatter.add_shape(
                    type="rect", xref="x", yref="y",
                    x0=sim_thresh, y0=0, x1=1.0, 
                    y1=plot_df_quant['activity_difference'].max() * 1.1,
                    line=dict(color="Red", width=2, dash="dash"),
                    fillcolor="rgba(255,0,0,0.1)"
                )
                st.plotly_chart(fig_quant_scatter, use_container_width=True)
                st.markdown("---")
            
            st.markdown("#### ìƒì„¸ ë¶„ì„ ëª©ë¡")
            pair_options = [
                f"{idx+1}. {df_quant_valid.iloc[p['mol1_index']].get('ID', 'N/A')} vs {df_quant_valid.iloc[p['mol2_index']].get('ID', 'N/A')} "
                f"(ìœ ì‚¬ë„: {p['similarity']:.2f}, í™œì„±ì°¨ì´: {abs(df_quant_valid.iloc[p['mol1_index']].get(ref_activity_col, 0) - df_quant_valid.iloc[p['mol2_index']].get(ref_activity_col, 0)):.2f}, ë¶„ë¥˜ì°¨ì´ ì ìˆ˜: {p.get('activity_category_diff', 0)})"
                for idx, p in enumerate(pairs)
            ]
            selected_pair_str = st.selectbox("ë¶„ì„í•  ìŒì„ ì„ íƒí•˜ì„¸ìš”:", pair_options, key=f"pair_select_{tab_key}")
            if selected_pair_str:
                selected_idx = pair_options.index(selected_pair_str)
                pair_info = pairs[selected_idx]
                mol1 = df_quant_valid.iloc[pair_info['mol1_index']]
                mol2 = df_quant_valid.iloc[pair_info['mol2_index']]
                cliff_data_quant = {
                    'mol_1': mol1.to_dict(),
                    'mol_2': mol2.to_dict(),
                    'similarity': pair_info['similarity'],
                    'activity_difference': abs(mol1.get(ref_activity_col, 0) - mol2.get(ref_activity_col, 0)),
                    'structural_difference': get_structural_difference_keyword(mol1['SMILES'], mol2['SMILES']),
                    'is_stereoisomer': check_stereoisomers(mol1['SMILES'], mol2['SMILES']),
                    'mol1_properties': calculate_molecular_properties(mol1['mol']),
                    'mol2_properties': calculate_molecular_properties(mol2['mol']),
                    'same_scaffold': mol1.get('scaffold') == mol2.get('scaffold'),
                    'score': (abs(mol1.get(ref_activity_col, 0) - mol2.get(ref_activity_col, 0))) * (pair_info['similarity'] - sim_thresh) * (1 if mol1.get('scaffold') == mol2.get('scaffold') else 0.5)
                }
                process_and_display_pair(
                    idx=selected_idx, cliff_data=cliff_data_quant,
                    activity_col=ref_activity_col, tab_key=f"quantitative_{tab_key}",
                    target_name=target_name, api_key=api_key, llm_provider=llm_provider, selected_patent=selected_patent,
                    cell_line=cell_line
                )



# --- DB ì—°ë™ì„ ìœ„í•œ ë°ì´í„° ë¡œë”© í•¨ìˆ˜ ---
db_path = "patent_etl_pipeline/database/patent_data.db" 

@st.cache_data
def get_patent_list():
    """DBì—ì„œ ì „ì²´ íŠ¹í—ˆ ë²ˆí˜¸ ëª©ë¡ë§Œ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    db: Session = SessionLocal()
    try:
        patents = db.query(Patent.patent_number).order_by(Patent.patent_number.desc()).all()
        return [p[0] for p in patents] # íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¼ë°˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    except Exception as e:
        st.sidebar.error(f"DB íŠ¹í—ˆ ëª©ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return []
    finally:
        db.close()

@st.cache_data
def get_targets_for_patent(patent_number):
    """ìž…ë ¥ëœ íŠ¹í—ˆ ë²ˆí˜¸ì— í•´ë‹¹í•˜ëŠ” ëª¨ë“  íƒ€ê²Ÿì˜ ì´ë¦„ì„ DBì—ì„œ ì°¾ì•„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not patent_number: return []
    db: Session = SessionLocal()
    try:
        targets = db.query(Target.target_name)\
                    .join(Activity, Target.target_id == Activity.target_id)\
                    .join(Patent, Activity.patent_id == Patent.patent_id)\
                    .filter(Patent.patent_number == patent_number)\
                    .distinct().order_by(Target.target_name).all()
        return [t[0] for t in targets]
    except Exception as e:
        st.sidebar.error(f"íŠ¹í—ˆ '{patent_number}'ì˜ íƒ€ê²Ÿ ëª©ë¡ ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return []
    finally:
        db.close()

@st.cache_data
def get_data_for_patent_and_target(patent_number, target_name):
    """íŠ¹ì • íŠ¹í—ˆì™€ íŠ¹ì • íƒ€ê²Ÿì— ëŒ€í•œ ë°ì´í„°ë§Œ DBì—ì„œ JOINí•˜ì—¬ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    if not patent_number: return None  # íŠ¹í—ˆëŠ” í•„ìˆ˜
    db: Session = SessionLocal()
    try:
        # SQLAlchemyì˜ read_sql_queryë¥¼ ì‚¬ìš©í•˜ì—¬ DataFrameìœ¼ë¡œ ì§ì ‘ ë³€í™˜
        query = db.query(
                    Compound.smiles.label("SMILES"),
                    Compound.compound_id.label("ID"),
                    Target.target_name.label("Target"),
                    Patent.patent_number.label("Patent"),
                    Activity.ic50.label("IC50"),
                    Activity.pic50.label("pIC50"),
                    Activity.activity_category.label("Activity")
                ).join(Activity, Compound.compound_id == Activity.compound_id)\
                 .join(Target, Activity.target_id == Target.target_id)\
                 .join(Patent, Activity.patent_id == Patent.patent_id)\
                 .filter(Patent.patent_number == patent_number)
        
        # target_nameì´ ì§€ì •ëœ ê²½ìš°ì—ë§Œ íƒ€ê²Ÿ í•„í„° ì¶”ê°€
        if target_name:
            query = query.filter(Target.target_name == target_name)
        
        query = query.statement
        df = pd.read_sql_query(query, db.bind)
        return df
    except Exception as e:
        st.error(f"ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜: {e}")
        return None
    finally:
        db.close()

# --- Main App ---
def main():
    if not os.path.exists(DATABASE_PATH):
        st.title("ðŸš€ SAR ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸° ì„¤ì •")
        st.info("ìµœì´ˆ ì‹¤í–‰ì„ ìœ„í•´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìžë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤. ìž ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”...")
        try:
            init_db() # database.pyì˜ í•¨ìˆ˜ í˜¸ì¶œ
            st.success("ë°ì´í„°ë² ì´ìŠ¤ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!")
            st.info("ì´ì œ ETL ìŠ¤í¬ë¦½íŠ¸(run_etl.py)ë¥¼ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ì±„ì›Œì£¼ì‹œê±°ë‚˜, ì•± ë‚´ ë°ì´í„° ë¡œë“œ ê¸°ëŠ¥ì„ ì´ìš©í•´ ì£¼ì„¸ìš”.")
            st.rerun()
        except Exception as e:
            st.error(f"ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return # DB ìƒì„± í›„ ì¼ë‹¨ ì •ì§€

    with st.sidebar:
        st.title("AI SAR ë¶„ì„ ì‹œìŠ¤í…œ")
        st.info("AI ê¸°ë°˜ êµ¬ì¡°-í™œì„± ê´€ê³„(SAR) ë¶„ì„ ë° ì˜ˆì¸¡ ì†”ë£¨ì…˜ìž…ë‹ˆë‹¤.")   

        # --- ë°ì´í„° ë¡œë“œ UI ---
        with st.expander("ðŸ“š ë°ì´í„° ê´€ë¦¬ (ì‹ ê·œ íŠ¹í—ˆ ë¡œë“œ)", expanded=False):
            patent_number_input = st.text_input("íŠ¹í—ˆ ë²ˆí˜¸ ìž…ë ¥", placeholder="ì˜ˆ: 1020170094694")
            uploaded_file = st.file_uploader("íŠ¹í—ˆ ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ", type=["xlsx"])
            
            if st.button("ë°ì´í„°ë² ì´ìŠ¤ì— ì €ìž¥"):
                if patent_number_input and uploaded_file:
                    with st.spinner("ETL í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì¤‘... ì—‘ì…€ íŒŒì¼ì„ ì½ê³  DBì— ì €ìž¥í•©ë‹ˆë‹¤."):
                        # ì—…ë¡œë“œëœ íŒŒì¼ì„ ìž„ì‹œ ì €ìž¥í•˜ì§€ ì•Šê³  ë©”ëª¨ë¦¬ì—ì„œ ë°”ë¡œ ì‚¬ìš©
                        file_buffer = io.BytesIO(uploaded_file.getvalue())
                        
                        # run_etl.pyì˜ í•¨ìˆ˜ í˜¸ì¶œ
                        progress_bar = st.progress(0, text="ETL ì‹œìž‘...")
                        success, message = run_etl(patent_number_input, file_buffer, progress_bar)
                        
                        if success:
                            st.success(message)
                            # ë“œë¡­ë‹¤ìš´ ëª©ë¡ì„ ì—…ë°ì´íŠ¸í•˜ê¸° ìœ„í•´ get_patent_list í•¨ìˆ˜ì˜ ìºì‹œë¥¼ ì§€ì›ë‹ˆë‹¤.
                            get_patent_list.clear()
                            st.rerun()
                        else:
                            st.error(message)
                else:
                    st.warning("íŠ¹í—ˆ ë²ˆí˜¸ì™€ ì—‘ì…€ íŒŒì¼ì„ ëª¨ë‘ ìž…ë ¥/ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
 
        st.header("ðŸ“ ë°ì´í„° ì„ íƒ")
        
        # 1. íŠ¹í—ˆ ë²ˆí˜¸ ìž…ë ¥ (DBì— ìžˆëŠ” ëª©ë¡ì—ì„œ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ìž…ë ¥)
        patent_list = get_patent_list()
        selected_patent = st.selectbox("1. ë¶„ì„í•  íŠ¹í—ˆ ë²ˆí˜¸ë¥¼ ì„ íƒí•˜ì„¸ìš”:", options=[""] + patent_list)
        
        # 2. ì„ íƒëœ íŠ¹í—ˆì— í¬í•¨ëœ íƒ€ê²Ÿ ëª©ë¡ í‘œì‹œ
        selected_target = None
        if selected_patent:
            target_list = get_targets_for_patent(selected_patent)
            if target_list:
                selected_target = st.selectbox("2. ë¶„ì„í•  íƒ€ê²Ÿì„ ì„ íƒí•˜ì„¸ìš”:", options=[""] + target_list)
            else:
                st.warning(f"'{selected_patent}' íŠ¹í—ˆì— ëŒ€í•œ íƒ€ê²Ÿ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.header("âš™ï¸ AI ëª¨ë¸ ì„¤ì •")
        # íŠ¹í—ˆë³„ ê¸°ë³¸ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ PDB ID ì„¤ì •
        # 1020170094694 íŠ¹í—ˆì˜ ê²½ìš°ì—ë§Œ 6G6Kë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
        default_target_pdb = "6G6K" if selected_patent and "1020170094694" in selected_patent else ""
        target_name_input = st.text_input("ë¶„ì„ ëŒ€ìƒ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ (PDB ID)", value=default_target_pdb, 
                                         help="íƒ€ê²Ÿ ë‹¨ë°±ì§ˆì˜ PDB IDë¥¼ ìž…ë ¥í•˜ì„¸ìš”. ì˜ˆ: 6G6K, 1M17, 4ZAU ë“±")
        llm_provider = st.selectbox("LLM ê³µê¸‰ìž ì„ íƒ:", ("OpenAI", "Gemini"))
        api_key = st.text_input("API í‚¤ ìž…ë ¥:", type="password", placeholder="OpenAI ë˜ëŠ” Gemini API í‚¤")

    # --- íƒ­ êµ¬ì¡° ì •ì˜ ---
    tab_titles = ["ì‹¤ì‹œê°„ ë¶„ì„", "ë¶„ì„ ì´ë ¥ ì¡°íšŒ"]

    created_tabs = st.tabs(tab_titles)
    tab_map = {name: tab for name, tab in zip(tab_titles, created_tabs)}

    # --- íƒ­ 1: ì‹¤ì‹œê°„ ë¶„ì„ ---
    with tab_map["ì‹¤ì‹œê°„ ë¶„ì„"]:
        st.header("ì‹¤ì‹œê°„ ë¶„ì„ ëŒ€ì‹œë³´ë“œ")
        df, available_activity_cols = None, []

        # íŠ¹í—ˆê°€ ì„ íƒë˜ê³  íƒ€ê²Ÿ(selected_target)ì´ ì„ íƒë˜ì—ˆì„ ë•Œ ë°ì´í„° ë¡œë“œ
        # íƒ€ê²Ÿì€ ë°ì´í„° í•„í„°ë§ìš©, PDB IDëŠ” ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ìš©ìœ¼ë¡œ ê°ê° ì‚¬ìš©
        if selected_patent and selected_target:
            with st.spinner(f"íŠ¹í—ˆ '{selected_patent}'ì˜ '{selected_target}' íƒ€ê²Ÿ ë°ì´í„° ë¡œë”© ì¤‘..."):
                # 1. íŠ¹í—ˆì™€ ì„¸í¬ì£¼ì— ë§žëŠ” ë°ì´í„°ë¥¼ DBì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                df_from_db = get_data_for_patent_and_target(selected_patent, selected_target)

            if df_from_db is not None:
                # 2. ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ utils.pyì˜ load_data í•¨ìˆ˜ë¡œ í›„ì²˜ë¦¬í•©ë‹ˆë‹¤.
                df_processed, available_activity_cols = load_data(df_from_db)

                if df_processed is not None:
                    # 3. ë°ì´í„° ë¡œë“œ ì§í›„, ë¶„ì„ ì „ì— ì¤‘ë³µ í™”í•©ë¬¼ì„ ì œê±°í•©ë‹ˆë‹¤.
                    ref_col = available_activity_cols[0] if available_activity_cols else 'pIC50'
                    if ref_col in df_processed.columns:
                        # í™œì„±ë„ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
                        df_sorted = df_processed.sort_values(ref_col, ascending=False)
                        # SMILES ê¸°ì¤€ ì¤‘ë³µ ì œê±° (ê°€ìž¥ í™œì„±ë„ ë†’ì€ ë°ì´í„°ë§Œ ë‚¨ê¹€)
                        df = df_sorted.drop_duplicates(subset=['SMILES'], keep='first')
                    else:
                        # í™œì„± ì»¬ëŸ¼ì´ ì—†ì„ ê²½ìš°, ê·¸ëƒ¥ SMILES ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±°
                        df = df_processed.drop_duplicates(subset=['SMILES'], keep='first')

                    st.sidebar.success(f"ì´ {len(df_from_db)}ê°œ í–‰ ì¤‘ {len(df)}ê°œì˜ ê³ ìœ  í™”í•©ë¬¼ ë¡œë“œ ì™„ë£Œ!")

                    # 4. Activity ì»¬ëŸ¼ì´ ì—†ëŠ” ê²½ìš°, pIC50/pKi ê¸°ì¤€ìœ¼ë¡œ ìžë™ ìƒì„±í•©ë‹ˆë‹¤.
                    if 'Activity' not in df.columns and any(col in df.columns for col in ['pIC50', 'pKi']):
                        ref_col_act = 'pIC50' if 'pIC50' in df.columns else 'pKi'
                        conditions = [
                            (df[ref_col_act] > 7.0),
                            (df[ref_col_act] > 5.7) & (df[ref_col_act] <= 7.0),
                            (df[ref_col_act] > 5.0) & (df[ref_col_act] <= 5.7),
                            (df[ref_col_act] <= 5.0) | (df[ref_col_act].isna())
                        ]
                        labels = ['Highly Active', 'Moderately Active', 'Weakly Active', 'Inactive']
                        df['Activity'] = np.select(conditions, labels, default='Unclassified')
                        st.info("Info: pIC50/pKi ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ Activity ì»¬ëŸ¼ì„ ìƒˆë¡œ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")

        # ìµœì¢… ì²˜ë¦¬ëœ ë°ì´í„°(df)ê°€ ìžˆì„ ê²½ìš°ì—ë§Œ ë¶„ì„ UIë¥¼ ë Œë”ë§í•©ë‹ˆë‹¤.
        if df is not None:
            st.success(f"'{selected_target}' íƒ€ê²Ÿì— ëŒ€í•œ {len(df)}ê°œì˜ í™”í•©ë¬¼ ë°ì´í„° ë¶„ì„ ì¤€ë¹„ ì™„ë£Œ!")

            # PDB IDì™€ ì„¸í¬ì£¼ ì •ë³´ ê²€ì¦
            if not target_name_input:
                st.warning("íƒ€ê²Ÿ ë‹¨ë°±ì§ˆ PDB IDê°€ ìž…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ì´ ì œí•œë  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")
            
            # ë¶„ì„ í•¨ìˆ˜ì— ì „ë‹¬í•  ì •ë³´ë“¤
            target_protein_pdb = target_name_input  # ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ìš© PDB ID
            cell_line_name = selected_target        # ì‹¤í—˜ ì¡°ê±´ìš© ì„¸í¬ì£¼

            # SAR ë¶„ì„ UI (ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°ë§Œ í‘œì‹œ)
            if ONLINE_DISCUSSION_AVAILABLE:
                st.markdown("---")
                st.subheader("êµ¬ì¡°-í™œì„± ê´€ê³„ ë¶„ì„ (í™œì„± ì ˆë²½ íƒì§€)")
                render_quantitative_analysis_ui(df, available_activity_cols, 'advanced', target_protein_pdb, api_key, llm_provider, selected_patent, cell_line_name)
            else:
                st.error("ì˜¨ë¼ì¸ ë‹¤ê°ë„ ë¶„ì„ ì‹œìŠ¤í…œì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.info("ë¶„ì„ì„ ì‹œìž‘í•˜ë ¤ë©´ ì‚¬ì´ë“œë°”ì—ì„œ íŠ¹í—ˆì™€ íƒ€ê²Ÿì„ ëª¨ë‘ ì„ íƒí•˜ì„¸ìš”.")

    # --- íƒ­ 2: ë¶„ì„ ì´ë ¥ ì¡°íšŒ ---
    with tab_map["ë¶„ì„ ì´ë ¥ ì¡°íšŒ"]:
        st.header("ë¶„ì„ ì´ë ¥ ì¡°íšŒ")

        with st.spinner("ê³¼ê±° ë¶„ì„ ì´ë ¥ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘..."):
            history_df = get_analysis_history()

        if history_df.empty:
            st.info("ì €ìž¥ëœ ë¶„ì„ ì´ë ¥ì´ ì—†ìŠµë‹ˆë‹¤. 'ì‹¤ì‹œê°„ ë¶„ì„' íƒ­ì—ì„œ ë¶„ì„ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ì €ìž¥í•´ì£¼ì„¸ìš”.")
        else:
            st.info(f"ì´ {len(history_df)}ê°œì˜ ë¶„ì„ ì´ë ¥ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            
            search_id = st.text_input("ê²€ìƒ‰í•  í™”í•©ë¬¼ ID (compound_id_1 ë˜ëŠ” compound_id_2):")
            
            display_df = history_df
            if search_id:
                try:
                    search_id_int = int(search_id)
                    display_df = history_df[
                        (history_df['compound_id_1'] == search_id_int) | 
                        (history_df['compound_id_2'] == search_id_int)
                    ]
                except ValueError:
                    st.warning("IDëŠ” ìˆ«ìžë¡œ ìž…ë ¥í•´ì£¼ì„¸ìš”.")

            # í…Œì´ë¸” í‘œì‹œ ì „ì— ì‹œê°„ì„ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
            if not display_df.empty and 'analysis_timestamp' in display_df.columns:
                from datetime import timedelta
                display_df_copy = display_df.copy()
                display_df_copy['analysis_timestamp'] = display_df_copy['analysis_timestamp'] + timedelta(hours=9)
                display_df_copy['analysis_timestamp'] = display_df_copy['analysis_timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')
                st.dataframe(display_df_copy)
            else:
                st.dataframe(display_df)

            st.markdown("---")
            st.subheader("ìƒì„¸ ì •ë³´ ë³´ê¸°")
            
            # ê²€ìƒ‰ ê²°ê³¼ê°€ ìžˆìœ¼ë©´ ê²€ìƒ‰ ê²°ê³¼ ë‚´ì—ì„œ, ì—†ìœ¼ë©´ ì „ì²´ ì´ë ¥ ë‚´ì—ì„œ ì„ íƒ
            detail_options = [""] + display_df['analysis_id'].tolist()
            selected_analysis_id = st.selectbox(
                "ìƒì„¸ížˆ ë³¼ ë¶„ì„ IDë¥¼ ì„ íƒí•˜ì„¸ìš”:", 
                options=detail_options
            )

            if selected_analysis_id:
                detail_data = history_df[history_df['analysis_id'] == selected_analysis_id].iloc[0]
                
                # UTC ì‹œê°„ì„ í•œêµ­ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                from datetime import timedelta
                
                # pandas Timestampì— 9ì‹œê°„ ë”í•˜ê¸°
                kst_time = detail_data['analysis_timestamp'] + timedelta(hours=9)
                formatted_time = kst_time.strftime('%Y-%m-%d %H:%M:%S')
                
                st.json({
                    "ë¶„ì„ ID": detail_data['analysis_id'],
                    "ë¶„ì„ ì‹œê°„": formatted_time,
                    "ë¶„ì„ ìŒ": f"ID {detail_data['compound_id_1']} vs ID {detail_data['compound_id_2']}",
                    "ìœ ì‚¬ë„": f"{detail_data['similarity']:.3f}" if pd.notna(detail_data['similarity']) else "N/A",
                    "í™œì„± ì°¨ì´": f"{detail_data['activity_difference']:.3f}" if pd.notna(detail_data['activity_difference']) else "N/A",
                    "ì ìˆ˜": f"{detail_data['score']:.2f}" if pd.notna(detail_data['score']) else "N/A",
                    "ë¶„ì„ ì—ì´ì „íŠ¸": detail_data['agent_name']
                })

                st.markdown("##### AI ìƒì„± ê°€ì„¤/ë¦¬í¬íŠ¸")
                try:
                    report_json = json.loads(detail_data['hypothesis_text'])
                    st.json(report_json)
                except (json.JSONDecodeError, TypeError):
                    st.info(detail_data['hypothesis_text'] or "ì €ìž¥ëœ ê°€ì„¤ì´ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
