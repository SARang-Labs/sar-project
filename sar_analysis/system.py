"""
SAR ë¶„ì„ ì‹œìŠ¤í…œ ë©”ì¸ ë¡œì§

ì´ ëª¨ë“ˆì€ Co-Scientist ë°©ë²•ë¡ ì„ ì‚¬ìš©í•œ ì „ë¬¸ê°€ í˜‘ì—… ì‹œìŠ¤í…œì˜ í•µì‹¬ ë¡œì§ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
Activity Cliff ìŒì— ëŒ€í•´ ì—¬ëŸ¬ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ê°€ í˜‘ì—…í•˜ì—¬ êµ¬ì¡°-í™œì„± ê´€ê³„ ê°€ì„¤ì„ ìƒì„±í•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.

ì£¼ìš” êµ¬ì„±ìš”ì†Œ:
- ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ: run_online_discussion_system()
- ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜: display_simplified_results(), display_docking_results()
- ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„: prepare_shared_context()
- ì „ë¬¸ê°€ ìƒì„± ë‹¨ê³„: generation_phase()

Co-Scientist ì›Œí¬í”Œë¡œìš°:
1. ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì‹¤í—˜ ë°ì´í„°, ë„í‚¹ ê²°ê³¼)
2. ë‹¤í•™ì œ ì „ë¬¸ê°€ ê°€ì„¤ ìƒì„± (êµ¬ì¡°í™”í•™, ìƒì²´ë¶„ììƒí˜¸ì‘ìš©, QSAR)
3. ê°€ì„¤ í‰ê°€ ë° ì¢…í•©
4. ê²°ê³¼ ì‹œê°í™” ë° í‘œì‹œ
"""

# === í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì™¸ë¶€ íŒ¨í‚¤ì§€ ===
import sys
import os
import time
from typing import Dict, List, Any
import streamlit as st

# === í”„ë¡œì íŠ¸ ë‚´ë¶€ ëª¨ë“ˆ ===
# utilsì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ import
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils import get_activity_cliff_summary

from .llm_client import UnifiedLLMClient
from .experts import (
    StructuralChemistryExpert,
    BiomolecularInteractionExpert,
    QSARExpert,
    HypothesisEvaluationExpert
)

# === ì‹œê°ì  í‘œì‹œ í•¨ìˆ˜ë“¤ ===
def display_expert_result(result: Dict):
    """
    ê° ì „ë¬¸ê°€ ê²°ê³¼ í‘œì‹œ

    ê°œë³„ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ì˜ ë¶„ì„ ê²°ê³¼ë¥¼ Streamlit UIì— í‘œì‹œí•©ë‹ˆë‹¤.
    ìƒì„±ëœ ê°€ì„¤ê³¼ í•µì‹¬ ì¸ì‚¬ì´íŠ¸ë¥¼ í™•ì¥ ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì œê³µí•©ë‹ˆë‹¤.

    Args:
        result (Dict): ì „ë¬¸ê°€ ë¶„ì„ ê²°ê³¼
            - agent_name: ì „ë¬¸ê°€ëª…
            - hypothesis: ìƒì„±ëœ ê°€ì„¤
            - key_insights: í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ëª©ë¡
    """
    with st.expander(f"{result['agent_name']} ê²°ê³¼", expanded=True):
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.write("**ìƒì„±ëœ ê°€ì„¤:**")
            st.write(result['hypothesis'][:300] + "..." if len(result['hypothesis']) > 300 else result['hypothesis'])
            
        with col2:
            st.write("**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**")
            for insight in result['key_insights'][:3]:
                st.write(f"â€¢ {insight}")


# === ë©”ì¸ ì˜¨ë¼ì¸ í† ë¡  ì‹œìŠ¤í…œ í•¨ìˆ˜ ===
def run_online_discussion_system(selected_cliff: Dict, target_name: str, api_key: str, llm_provider: str = "OpenAI", cell_line: str = None) -> Dict:
    """
    Co-Scientist ë°©ë²•ë¡  ê¸°ë°˜ SAR ë¶„ì„ ì‹œìŠ¤í…œ

    Activity Cliff ìŒì— ëŒ€í•´ ë‹¤í•™ì œ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ë“¤ì´ í˜‘ì—…í•˜ì—¬
    êµ¬ì¡°-í™œì„± ê´€ê³„ ê°€ì„¤ì„ ìƒì„±í•˜ê³  í‰ê°€í•˜ëŠ” ë©”ì¸ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

    ì›Œí¬í”Œë¡œìš°:
    1. ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ (ì‹¤í—˜ ë°ì´í„°, ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜)
    2. ì „ë¬¸ê°€ ê°€ì„¤ ìƒì„± (êµ¬ì¡°í™”í•™, ìƒì²´ë¶„ììƒí˜¸ì‘ìš©, QSAR)
    3. ê°€ì„¤ í‰ê°€ ë° í’ˆì§ˆ ê²€ì¦
    4. ìµœì¢… ê²°ê³¼ ì¢…í•© ë° ë°˜í™˜

    Args:
        selected_cliff (Dict): Activity Cliff ìŒ ë°ì´í„°
        target_name (str): íƒ€ê²Ÿ ë‹¨ë°±ì§ˆëª…
        api_key (str): LLM API í‚¤
        llm_provider (str): LLM ê³µê¸‰ì ("OpenAI" ë˜ëŠ” "Gemini")
        cell_line (str, optional): ì„¸í¬ì£¼ ì •ë³´

    Returns:
        Dict: ìµœì¢… ë¶„ì„ ê²°ê³¼
            - best_hypothesis: ìµœê³  í’ˆì§ˆ ê°€ì„¤
            - all_hypotheses: ëª¨ë“  ì „ë¬¸ê°€ ê°€ì„¤
            - evaluations: ê°€ì„¤ í‰ê°€ ê²°ê³¼
            - shared_context: ê³µìœ  ì»¨í…ìŠ¤íŠ¸
            - processing_time: ì²˜ë¦¬ ì‹œê°„
    """
    
    start_time = time.time()
    
    # í†µí•© LLM í´ë¼ì´ì–¸íŠ¸ ìƒì„±
    llm_client = UnifiedLLMClient(api_key, llm_provider)
    
    # st.markdown("**Co-Scientist ë°©ë²•ë¡  ê¸°ë°˜ SAR ë¶„ì„**")
    st.markdown(f"3ëª…ì˜ ì „ë¬¸ê°€ Agentê°€ ë…ë¦½ì ìœ¼ë¡œ ë¶„ì„í•œ í›„ í‰ê°€ë¥¼ í†µí•´ ìµœê³  í’ˆì§ˆì˜ ê°€ì„¤ì„ ìƒì„±í•©ë‹ˆë‹¤.")
    
    # Phase 1: ë°ì´í„° ì¤€ë¹„ + ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ í†µí•©
    st.info("**Phase 1: ë°ì´í„° ì¤€ë¹„** - ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±")
    shared_context = prepare_shared_context(selected_cliff, target_name, cell_line)
    
    # ì»¨í…ìŠ¤íŠ¸ ì •ë³´ í‘œì‹œ
    with st.expander("ë¶„ì„ ëŒ€ìƒ ì •ë³´", expanded=False):
        cliff_summary = shared_context['cliff_summary']
        st.write(f"**ê³ í™œì„± í™”í•©ë¬¼:** {cliff_summary['high_activity_compound']['id']} (pIC50: {cliff_summary['high_activity_compound']['pic50']})")
        st.code(cliff_summary['high_activity_compound']['smiles'], language=None)
        st.write(f"**ì €í™œì„± í™”í•©ë¬¼:** {cliff_summary['low_activity_compound']['id']} (pIC50: {cliff_summary['low_activity_compound']['pic50']})")
        st.code(cliff_summary['low_activity_compound']['smiles'], language=None)
        st.write(f"**í™œì„±ë„ ì°¨ì´:** {cliff_summary['cliff_metrics']['activity_difference']}")
    
    # ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ í‘œì‹œ
    cliff_summary = shared_context.get('cliff_summary', {})
    if cliff_summary:
        high_compound = cliff_summary.get('high_activity_compound', {})
        low_compound = cliff_summary.get('low_activity_compound', {})
        target_name = shared_context.get('target_name', 'EGFR')
        
        # ë„í‚¹ ê²°ê³¼ ìƒì„± (get_docking_context í•¨ìˆ˜ ì‚¬ìš©)
        from utils import get_docking_context
        docking_results = get_docking_context(high_compound.get('smiles'), low_compound.get('smiles'), target_name)
        
        with st.expander("ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown(f"**í™”í•©ë¬¼ 1 (ë‚®ì€ í™œì„±, ID: {low_compound.get('id', 'N/A')})**")
                docking1 = docking_results['compound2']
                st.markdown(f"- **ê²°í•© ì¹œí™”ë„:** {docking1['binding_affinity_kcal_mol']} kcal/mol")
                st.markdown(f"- **ìˆ˜ì†Œê²°í•©:** {', '.join(docking1['interaction_fingerprint']['Hydrogenbonds']) if docking1['interaction_fingerprint']['Hydrogenbonds'] else 'ì—†ìŒ'}")
                st.markdown(f"- **ì†Œìˆ˜ì„± ìƒí˜¸ì‘ìš©:** {', '.join(docking1['interaction_fingerprint']['Hydrophobic']) if docking1['interaction_fingerprint']['Hydrophobic'] else 'ì—†ìŒ'}")
                st.markdown(f"- **í• ë¡œê²ê²°í•©:** {', '.join(docking1['interaction_fingerprint']['Halogenbonds']) if docking1['interaction_fingerprint']['Halogenbonds'] else 'ì—†ìŒ'}")
            
            with col2:
                st.markdown(f"**í™”í•©ë¬¼ 2 (ë†’ì€ í™œì„±, ID: {high_compound.get('id', 'N/A')})**")
                docking2 = docking_results['compound1']
                st.markdown(f"- **ê²°í•© ì¹œí™”ë„:** {docking2['binding_affinity_kcal_mol']} kcal/mol")
                st.markdown(f"- **ìˆ˜ì†Œê²°í•©:** {', '.join(docking2['interaction_fingerprint']['Hydrogenbonds']) if docking2['interaction_fingerprint']['Hydrogenbonds'] else 'ì—†ìŒ'}")
                st.markdown(f"- **ì†Œìˆ˜ì„± ìƒí˜¸ì‘ìš©:** {', '.join(docking2['interaction_fingerprint']['Hydrophobic']) if docking2['interaction_fingerprint']['Hydrophobic'] else 'ì—†ìŒ'}")
                st.markdown(f"- **í• ë¡œê²ê²°í•©:** {', '.join(docking2['interaction_fingerprint']['Halogenbonds']) if docking2['interaction_fingerprint']['Halogenbonds'] else 'ì—†ìŒ'}")
    
    # Phase 2: Generation - 3ê°œ ì „ë¬¸ê°€ ë…ë¦½ ë¶„ì„
    st.markdown("---")
    st.info("**Phase 2: Generation** - 3ëª…ì˜ ì „ë¬¸ê°€ Agentê°€ ê°ìì˜ ê´€ì ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ ê°€ì„¤ì„ ìƒì„±í•©ë‹ˆë‹¤")
    domain_hypotheses = generation_phase(shared_context, llm_client)
    
    # Phase 3: ì¢…í•© í‰ê°€ ë° ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
    st.markdown("---")
    # st.info("**Phase 3: ì¢…í•© í‰ê°€** - í‰ê°€ ì „ë¬¸ Agentê°€ ëª¨ë“  ê°€ì„¤ì˜ ì¥ì ì„ í†µí•©í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤")
    
    # í‰ê°€ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ ì´ˆê¸°í™” (ê¸°ì¡´ í´ë˜ìŠ¤ ì¬ì‚¬ìš©)
    evaluator = HypothesisEvaluationExpert(llm_client)
    
    # ìƒˆë¡œìš´ ì¢…í•© í‰ê°€ ë°©ì‹ ì‚¬ìš©
    evaluation_report = evaluator.evaluate_hypotheses(domain_hypotheses, shared_context)
    
    # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
    final_report = {
        'final_hypothesis': evaluation_report.get('final_hypothesis', ''),
        'individual_evaluations': evaluation_report.get('individual_evaluations', []),
        'domain_hypotheses': domain_hypotheses,  # ë„í‚¹ ê²°ê³¼ê°€ í¬í•¨ëœ ê°€ì„¤ë“¤ ì¶”ê°€
        'synthesis_metadata': evaluation_report.get('synthesis_metadata', {}),
        'process_metadata': {
            'total_time': time.time() - start_time,
            'total_agents': len(domain_hypotheses),
            'analysis_method': 'Co-Scientist ì¢…í•© í‰ê°€ ë°©ë²•ë¡ ',
            'synthesis_approach': True
        },
        'literature_context': shared_context.get('literature_context'),
        'cliff_context': shared_context.get('cliff_summary')
    }
    
    st.markdown("---")
    st.info("**Phase 4: ê°€ì„¤ ë¦¬í¬íŠ¸ ìƒì„± ë° ë¶„ì„ ê²°ê³¼**")
    st.success(f"**ì´ ì†Œìš” ì‹œê°„:** {final_report['process_metadata']['total_time']:.1f}ì´ˆ")
    
    # ìµœì¢… ê²°ê³¼ í‘œì‹œ
    display_simplified_results(final_report)
    
    return final_report


def display_simplified_results(final_report: Dict):
    """
    ì¢…í•© ë¦¬í¬íŠ¸ í˜•ì‹ìœ¼ë¡œ ìµœì¢… ê²°ê³¼ í‘œì‹œ

    Co-Scientist ì‹œìŠ¤í…œì˜ ì „ì²´ ë¶„ì„ ê²°ê³¼ë¥¼ ì‚¬ìš©ì ì¹œí™”ì ì¸ í˜•íƒœë¡œ
    Streamlit UIì— í‘œì‹œí•©ë‹ˆë‹¤. ìµœì¢… ì¢…í•© ê°€ì„¤, ê°œë³„ ì „ë¬¸ê°€ í‰ê°€,
    ë„í‚¹ ê²°ê³¼ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ì œê³µí•©ë‹ˆë‹¤.

    Args:
        final_report (Dict): ìµœì¢… ë¶„ì„ ê²°ê³¼
            - final_hypothesis: ìµœì¢… ì¢…í•© ê°€ì„¤
            - individual_evaluations: ê°œë³„ ì „ë¬¸ê°€ í‰ê°€
            - domain_hypotheses: ì „ë¬¸ê°€ë³„ ê°€ì„¤
            - process_metadata: ì²˜ë¦¬ ë©”íƒ€ë°ì´í„°
    """
    
    # ìµœì¢… ì¢…í•© ê°€ì„¤ í‘œì‹œ
    final_hypothesis = final_report.get('final_hypothesis', '')
    if final_hypothesis:
        st.markdown(final_hypothesis)
    else:
        st.warning("ìµœì¢… ì¢…í•© ê°€ì„¤ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        # ëŒ€ì•ˆìœ¼ë¡œ ê°œë³„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
        individual_evaluations = final_report.get('individual_evaluations', [])
        if individual_evaluations:
            st.markdown("## ğŸ“Š ê°œë³„ ì „ë¬¸ê°€ ë¶„ì„ ìš”ì•½")
            
            for eval_result in individual_evaluations:
                with st.expander(f"ğŸ“ {eval_result['agent_name']} ìƒì„¸ ë¶„ì„", expanded=False):
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.write("**ì›ë³¸ ê°€ì„¤:**")
                        hypothesis_text = eval_result['original_hypothesis'].get('hypothesis', '')
                        if len(hypothesis_text) > 300:
                            st.write(hypothesis_text[:300] + "...")
                        else:
                            st.write(hypothesis_text)
                    
                    with col2:
                        if eval_result.get('strengths'):
                            st.write("**ì£¼ìš” ê°•ì :**")
                            for strength in eval_result['strengths'][:2]:
                                st.write(f"â€¢ {strength}")
                        
                        if eval_result.get('key_insights'):
                            st.write("**í•µì‹¬ ì¸ì‚¬ì´íŠ¸:**")
                            for insight in eval_result['key_insights'][:2]:
                                st.write(f"â€¢ {insight}")
    
    # ì¢…í•© í”„ë¡œì„¸ìŠ¤ ë©”íƒ€ë°ì´í„° í‘œì‹œ
    st.markdown("---")
    
    col1, col2, col3, col4 = st.columns(4)
    
    metadata = final_report.get('process_metadata', {})
    synthesis_metadata = final_report.get('synthesis_metadata', {})
    
    with col1:
        st.metric("ì´ ì†Œìš”ì‹œê°„", f"{metadata.get('total_time', 0):.1f}ì´ˆ")
    with col2:
        st.metric("ì°¸ì—¬ ì „ë¬¸ê°€", f"{metadata.get('total_agents', 0)}ëª…")
    with col3:
        st.metric("í†µí•© ê°•ì ", f"{synthesis_metadata.get('total_strengths_considered', 0)}ê°œ")
    with col4:
        st.metric("í†µí•© ì¸ì‚¬ì´íŠ¸", f"{synthesis_metadata.get('total_insights_integrated', 0)}ê°œ")


def prepare_shared_context(selected_cliff: Dict, target_name: str, cell_line: str = None) -> Dict:
    """
    ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„

    ì „ë¬¸ê°€ ì—ì´ì „íŠ¸ë“¤ì´ ê³µí†µìœ¼ë¡œ ì‚¬ìš©í•  ì»¨í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤.
    Activity Cliff ìš”ì•½ ì •ë³´ì™€ ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.

    Args:
        selected_cliff (Dict): Activity Cliff ìŒ ë°ì´í„°
        target_name (str): íƒ€ê²Ÿ ë‹¨ë°±ì§ˆëª…
        cell_line (str, optional): ì„¸í¬ì£¼ ì •ë³´

    Returns:
        Dict: ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ì •ë³´
            - cliff_summary: Activity Cliff ìš”ì•½
            - target_name: íƒ€ê²Ÿ ë‹¨ë°±ì§ˆëª…
            - literature_context: ë„í‚¹ ê²°ê³¼ (ì„ íƒì )
    """
    """ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ì„ í™œìš©í•œ ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„ - ê°•í™”ëœ êµ¬ì¡° ê¸°ë°˜ ê·¼ê±° ì œê³µ"""
    
    # ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    from utils import get_docking_context
    docking_context = get_docking_context(
        selected_cliff['mol_1']['SMILES'],
        selected_cliff['mol_2']['SMILES'],
        target_name
    )
    cliff_summary = get_activity_cliff_summary(selected_cliff)
    
    # ë„í‚¹ ì»¨í…ìŠ¤íŠ¸ í’ˆì§ˆ í–¥ìƒ
    if docking_context and isinstance(docking_context, dict):
        # ë„í‚¹ ì •ë³´ ê°•í™”
        enhanced_docking = docking_context.copy()
        enhanced_docking['context_type'] = 'Docking Simulation Result'
        enhanced_docking['usage_instruction'] = f"ì´ ë„í‚¹ ê²°ê³¼ë¥¼ {target_name} íƒ€ê²Ÿì— ëŒ€í•œ Activity Cliff ë¶„ì„ì˜ êµ¬ì¡°ì  ê·¼ê±°ë¡œ í™œìš©í•˜ì„¸ìš”"
        docking_context = enhanced_docking
    
    # ì„¸í¬ì£¼ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ìˆëŠ” ê²½ìš°)
    cell_line_context = None
    if cell_line:
        try:
            from utils import get_cell_line_info, get_cell_line_context_prompt
            cell_line_info = get_cell_line_info(cell_line)
            cell_line_context = {
                'cell_line_name': cell_line,
                'cell_line_info': cell_line_info,
                'context_prompt': get_cell_line_context_prompt(cell_line_info, target_name)
            }
        except ImportError:
            # utilsì— ì„¸í¬ì£¼ í•¨ìˆ˜ê°€ ì—†ì„ ê²½ìš° ê¸°ë³¸ ì •ë³´ë§Œ
            cell_line_context = {
                'cell_line_name': cell_line,
                'cell_line_info': {'characteristics': f'Cell line: {cell_line}'},
                'context_prompt': f"**ì„¸í¬ì£¼ ì»¨í…ìŠ¤íŠ¸:** í™œì„±ë„ëŠ” {cell_line} ì„¸í¬ì£¼ì—ì„œ ì¸¡ì •ë¨"
            }
    
    # ëª¨ë“  ì—ì´ì „íŠ¸ê°€ ê³µìœ í•  í†µí•© ì»¨í…ìŠ¤íŠ¸
    shared_context = {
        'cliff_data': selected_cliff,
        'cliff_summary': cliff_summary,
        'literature_context': docking_context,  # ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
        'target_name': target_name,             # PDB ID (ì˜ˆ: 6G6K)
        'cell_line_context': cell_line_context, # ì„¸í¬ì£¼ ì •ë³´
        'timestamp': time.time(),
        'context_quality': 'Enhanced' if docking_context else 'Basic',
        'evidence_level': 'Docking-backed' if docking_context else 'Data-only'
    }
    
    return shared_context


def generation_phase(shared_context: Dict, llm_client: UnifiedLLMClient) -> List[Dict]:
    """
    ì „ë¬¸ê°€ ê°€ì„¤ ìƒì„± ë‹¨ê³„

    3ëª…ì˜ ì „ë¬¸ê°€ ì—ì´ì „íŠ¸(êµ¬ì¡°í™”í•™, ìƒì²´ë¶„ììƒí˜¸ì‘ìš©, QSAR)ê°€
    ë…ë¦½ì ìœ¼ë¡œ ê°€ì„¤ì„ ìƒì„±í•˜ëŠ” ë‹¨ê³„ì…ë‹ˆë‹¤.

    Args:
        shared_context (Dict): ê³µìœ  ì»¨í…ìŠ¤íŠ¸ ì •ë³´
        llm_client (UnifiedLLMClient): LLM í´ë¼ì´ì–¸íŠ¸

    Returns:
        List[Dict]: ì „ë¬¸ê°€ë³„ ê°€ì„¤ ëª©ë¡
    """
    """3ê°œ ë„ë©”ì¸ ì „ë¬¸ê°€ ìˆœì°¨ ì‹¤í–‰ (ê°„ì†Œí™” ë²„ì „)"""
    experts = [
        StructuralChemistryExpert(llm_client),
        BiomolecularInteractionExpert(llm_client),
        QSARExpert(llm_client)
    ]
    
    domain_hypotheses = []
    progress_bar = st.progress(0)
    
    for i, expert in enumerate(experts):
        try:
            with st.spinner(f"{expert.__class__.__name__} ê°€ì„¤ ìƒì„± ì¤‘..."):
                result = expert.generate(shared_context)
                domain_hypotheses.append(result)
                
                # ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸
                progress = (i + 1) / len(experts)
                progress_bar.progress(progress)
                
                # ê° ì „ë¬¸ê°€ ê²°ê³¼ ì¦‰ì‹œ í‘œì‹œ
                display_expert_result(result)
        except Exception as e:
            st.error(f"{expert.__class__.__name__} ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            # ê¸°ë³¸ ê²°ê³¼ ìƒì„±
            result = {
                'agent_type': 'error',
                'agent_name': f"âŒ {expert.__class__.__name__}",
                'hypothesis': f"ê°€ì„¤ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                'key_insights': ['ì˜¤ë¥˜ ë°œìƒ'],
                'reasoning_steps': ['ì˜¤ë¥˜ë¡œ ì¸í•œ ì¤‘ë‹¨'],
                'timestamp': time.time()
            }
            domain_hypotheses.append(result)
    
    progress_bar.empty()  # Phase 2 ì§„í–‰ë°” ìˆ¨ê¸°ê¸°
    return domain_hypotheses


def display_docking_results(docking_analysis: dict, agent_name: str):
    """
    ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ í‘œì‹œ

    ìƒì²´ë¶„ì ìƒí˜¸ì‘ìš© ì „ë¬¸ê°€ì˜ ë„í‚¹ ë¶„ì„ ê²°ê³¼ë¥¼
    ì‹œê°ì ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.

    Args:
        docking_analysis (dict): ë„í‚¹ ë¶„ì„ ê²°ê³¼
        agent_name (str): ì „ë¬¸ê°€ëª… (í˜„ì¬ ë¯¸ì‚¬ìš©)
    """
    """ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‘œì‹œ"""
    if not docking_analysis:
        return
    
    # ë„í‚¹ ê²°ê³¼ë¥¼ í† ê¸€(expander) ì•ˆì— ë„£ê¸°
    with st.expander("ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ë¶„ì„ ê²°ê³¼ (ìƒì„¸ ë³´ê¸°)", expanded=False):
        
        # ì „ì²´ ê²°ê³¼ë¥¼ í•œ í™”ë©´ì— í‘œì‹œ
        if 'high_active_docking' in docking_analysis and 'low_active_docking' in docking_analysis:
            high_result = docking_analysis['high_active_docking']
            low_result = docking_analysis['low_active_docking']
            
            # 1. ê²°í•© ì¹œí™”ë„ ë° Ki ê°’ ë¹„êµ (ì‘ì€ í°íŠ¸ë¡œ)
            st.markdown("**1) ê²°í•© ì¹œí™”ë„ ë¶„ì„**")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.write("ê³ í™œì„± í™”í•©ë¬¼")
                st.write(f"â€¢ ê²°í•© ì¹œí™”ë„: {high_result['binding_affinity']:.1f} kcal/mol")
            
            with col2:
                st.write("ì €í™œì„± í™”í•©ë¬¼")  
                st.write(f"â€¢ ê²°í•© ì¹œí™”ë„: {low_result['binding_affinity']:.1f} kcal/mol")
            
            # 2. ë¹„êµ ë¶„ì„ ê²°ê³¼
            if 'comparative_analysis' in docking_analysis:
                comp_analysis = docking_analysis['comparative_analysis']
                
                with col3:
                    st.write("ì¹œí™”ë„ ì°¨ì´")
                    diff_value = comp_analysis['affinity_difference']
                    st.write(f"â€¢ ì°¨ì´: {abs(diff_value):.1f} kcal/mol")
                    st.write(f"â€¢ ë°©í–¥: {'ê³ í™œì„± > ì €í™œì„±' if diff_value < 0 else 'ì €í™œì„± > ê³ í™œì„±'}")
                
                with col4:
                    st.write("ì˜ˆì¸¡ ì •í™•ë„")
                    supports_cliff = comp_analysis.get('supports_activity_cliff', False)
                    activity_ratio = comp_analysis.get('predicted_activity_ratio', 1)
                    st.write(f"â€¢ í™œì„±ë¹„: {activity_ratio:.1f}ë°°")
                    st.write(f"â€¢ ì‹¤í—˜ ì¼ì¹˜: {'ì˜ˆ' if supports_cliff else 'ì•„ë‹ˆì˜¤'}")
            
            # 3. ë¶„ìê°„ ìƒí˜¸ì‘ìš© ë¶„ì„
            st.markdown("**2) ë‹¨ë°±ì§ˆ-ë¦¬ê°„ë“œ ìƒí˜¸ì‘ìš©**")
            
            interaction_names = {
                'hydrogen_bonds': 'ìˆ˜ì†Œê²°í•©',
                'hydrophobic': 'ì†Œìˆ˜ì„± ìƒí˜¸ì‘ìš©',
                'pi_stacking': 'Ï€-Ï€ ì ì¸µ',
                'electrostatic': 'ì •ì „ê¸° ìƒí˜¸ì‘ìš©'
            }
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("ê³ í™œì„± í™”í•©ë¬¼ ìƒí˜¸ì‘ìš©:")
                if high_result.get('interactions'):
                    for interaction_type, residues in high_result['interactions'].items():
                        if residues:
                            interaction_name = interaction_names.get(interaction_type, interaction_type)
                            residue_text = ', '.join(residues[:3])
                            if len(residues) > 3:
                                residue_text += f" ì™¸ {len(residues)-3}ê°œ"
                            st.write(f"â€¢ {interaction_name}: {residue_text}")
                else:
                    st.write("â€¢ ìƒí˜¸ì‘ìš© ë°ì´í„° ì—†ìŒ")
            
            with col2:
                st.write("ì €í™œì„± í™”í•©ë¬¼ ìƒí˜¸ì‘ìš©:")
                if low_result.get('interactions'):
                    for interaction_type, residues in low_result['interactions'].items():
                        if residues:
                            interaction_name = interaction_names.get(interaction_type, interaction_type)
                            residue_text = ', '.join(residues[:3])
                            if len(residues) > 3:
                                residue_text += f" ì™¸ {len(residues)-3}ê°œ"
                            st.write(f"â€¢ {interaction_name}: {residue_text}")
                else:
                    st.write("â€¢ ìƒí˜¸ì‘ìš© ë°ì´í„° ì—†ìŒ")
            
            # 4. ì¢…í•© í•´ì„
            st.markdown("**3) ë„í‚¹ ë¶„ì„ ì¢…í•© í•´ì„**")
            
            if 'comparative_analysis' in docking_analysis:
                comp_analysis = docking_analysis['comparative_analysis']
                diff_value = comp_analysis['affinity_difference']
                supports_cliff = comp_analysis.get('supports_activity_cliff', False)
                
                if supports_cliff and diff_value < -1.0:
                    interpretation = "ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ê°€ ì‹¤í—˜ì  í™œì„± ì°¨ì´ë¥¼ ì˜ ì„¤ëª…í•©ë‹ˆë‹¤. ê³ í™œì„± í™”í•©ë¬¼ì´ íƒ€ê²Ÿ ë‹¨ë°±ì§ˆê³¼ ë” ê°•í•œ ê²°í•©ì„ í˜•ì„±í•˜ì—¬ ë†’ì€ ìƒë¬¼í•™ì  í™œì„±ì„ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë©ë‹ˆë‹¤."
                elif not supports_cliff and abs(diff_value) < 1.0:
                    interpretation = "ë„í‚¹ ê²°ê³¼ë§Œìœ¼ë¡œëŠ” í™œì„± ì°¨ì´ë¥¼ ì™„ì „íˆ ì„¤ëª…í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤. ê²°í•© ì¹œí™”ë„ ì™¸ì— ë‹¨ë°±ì§ˆ ë™ì—­í•™, ì•Œë¡œìŠ¤í…Œë¦­ íš¨ê³¼, ë˜ëŠ” ADMET íŠ¹ì„± ì°¨ì´ê°€ ì£¼ìš” ì›ì¸ì¼ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤."
                elif diff_value > 1.0:
                    interpretation = "ë„í‚¹ ê²°ê³¼ê°€ ì‹¤í—˜ ë°ì´í„°ì™€ ìƒë°˜ë©ë‹ˆë‹¤. ì €í™œì„± í™”í•©ë¬¼ì´ ë” ê°•í•œ ê²°í•©ì„ ë³´ì´ë¯€ë¡œ, ê²°í•© í›„ ë‹¨ë°±ì§ˆ ê¸°ëŠ¥ ì¡°ì ˆ, ëŒ€ì‚¬ ì•ˆì •ì„±, ë˜ëŠ” ì„¸í¬ë§‰ íˆ¬ê³¼ì„± ë“± ë‹¤ë¥¸ ìš”ì¸ì˜ ì˜í–¥ì´ í´ ê²ƒìœ¼ë¡œ ì˜ˆìƒë©ë‹ˆë‹¤."
                else:
                    interpretation = "ë„í‚¹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ í•´ì„ì´ ë¶ˆëª…í™•í•©ë‹ˆë‹¤. ì¶”ê°€ì ì¸ ë¶„ìë™ì—­í•™ ì‹œë®¬ë ˆì´ì…˜ì´ë‚˜ ì‹¤í—˜ì  ê²€ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤."
                
                st.write(interpretation)
            
            # 5. ì¶”ê°€ ë¶„ì„ ì œì•ˆ
            st.markdown("**4) í›„ì† ë¶„ì„ ì œì•ˆ**")
            suggestions = [
                "ë¶„ìë™ì—­í•™(MD) ì‹œë®¬ë ˆì´ì…˜ì„ í†µí•œ ê²°í•© ì•ˆì •ì„± ë¶„ì„",
                "ììœ ì—ë„ˆì§€ ì„­ë™(FEP) ê³„ì‚°ìœ¼ë¡œ ì •ë°€í•œ ê²°í•© ì¹œí™”ë„ ì˜ˆì¸¡",
                "ë‹¨ë°±ì§ˆ-ë¦¬ê°„ë“œ ë³µí•©ì²´ì˜ ê²°í•© ëª¨ë“œ ìƒì„¸ ë¶„ì„",
                "ADMET ì˜ˆì¸¡ì„ í†µí•œ ì•½ë™í•™ì  íŠ¹ì„± ë¹„êµ"
            ]
            
            for i, suggestion in enumerate(suggestions, 1):
                st.write(f"{i}. {suggestion}")
