"""
ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  ì¸í„°í˜ì´ìŠ¤

ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” Streamlit UI:
1. ê° ì—ì´ì „íŠ¸ì˜ ìµœì´ˆ í”„ë¡¬í”„íŠ¸ì™€ ê°€ì„¤ì„ í† ê¸€ë¡œ í‘œì‹œ
2. 3ë²ˆì˜ í† ë¡  ê³¼ì •ì„ ì²´ê³„ì ìœ¼ë¡œ ì‹œê°í™”
3. ì§ì ‘ ì¸ìš© ê¸°ë°˜ íˆ¬ëª…í•œ í‰ê°€ ê³¼ì • í‘œì‹œ
4. ìµœì¢… ìµœì  í”„ë¡¬í”„íŠ¸ì™€ ê°€ì„¤ ì „ë¬¸ ê¹”ë”í•˜ê²Œ ì œì‹œ
"""

import streamlit as st
import json
from typing import Dict, List, Any, Optional
import sys
import os

# ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from llm_debate.debate.optimal_prompt_debate_manager import OptimalPromptDebateManager, OptimalPromptDebateState

class OptimalPromptDebateInterface:
    """
    ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  Streamlit ì¸í„°í˜ì´ìŠ¤
    
    ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ì„ ì •í™•íˆ êµ¬í˜„í•œ UI ì œê³µ
    """
    
    def __init__(self):
        self.debate_manager = OptimalPromptDebateManager()
    
    def show_interface(self, activity_cliff: Dict, context_info: Dict = None, target_name: str = ""):
        """ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  ì¸í„°í˜ì´ìŠ¤ í‘œì‹œ"""
        
        # API í‚¤ ì„¤ì •
        api_keys = self._get_api_keys()
        if not self._validate_api_keys(api_keys):
            st.error("API í‚¤ë¥¼ ëª¨ë‘ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            return
        
        # ì—ì´ì „íŠ¸ ì„¤ì •
        self.debate_manager.setup_agents(api_keys)
        
        # í† ë¡  ì‹¤í–‰ ë²„íŠ¼
        if st.button("ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  ì‹œì‘", type="primary"):
            
            # ì§„í–‰ ìƒí™© í‘œì‹œ
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            with st.spinner("ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡ ì„ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤..."):
                
                # í† ë¡  ì‹¤í–‰
                progress_bar.progress(10)
                
                debate_result = self.debate_manager.run_optimal_prompt_debate(
                    activity_cliff, context_info, target_name
                )
                
                progress_bar.progress(100)
                
                # ê²°ê³¼ í‘œì‹œ
                self._display_debate_results(debate_result)
    
    def _get_api_keys(self) -> Dict[str, str]:
        """API í‚¤ ì…ë ¥ ë°›ê¸°"""
        st.sidebar.markdown("## ğŸ”‘ API í‚¤ ì„¤ì •")
        
        api_keys = {}
        api_keys["openai"] = st.sidebar.text_input("OpenAI API Key", type="password")
        api_keys["gemini"] = st.sidebar.text_input("Google Gemini API Key", type="password")
        api_keys["futurehouse"] = st.sidebar.text_input("FutureHouse API Key", type="password")
        
        return api_keys
    
    def _validate_api_keys(self, api_keys: Dict[str, str]) -> bool:
        """API í‚¤ ìœ íš¨ì„± ê²€ì¦"""
        return all(api_keys.values())
    
    def _display_debate_results(self, debate_result: OptimalPromptDebateState):
        """í† ë¡  ê²°ê³¼ ì „ì²´ í‘œì‹œ"""
        
        # ì—ëŸ¬ ì²´í¬
        if debate_result.errors:
            st.error("í† ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ:")
            for error in debate_result.errors:
                st.error(f"- {error}")
            return
        
        st.success("ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡ ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # íƒ­ìœ¼ë¡œ êµ¬ì„±
        tab1, tab2, tab3, tab4 = st.tabs([
            "1ï¸âƒ£ ì´ˆê¸° í”„ë¡¬í”„íŠ¸ & ê°€ì„¤",
            "2ï¸âƒ£ í† ë¡  ê³¼ì •", 
            "3ï¸âƒ£ ìµœì¢… ìµœì  í”„ë¡¬í”„íŠ¸",
            "ğŸ“Š í† ë¡  ìš”ì•½"
        ])
        
        with tab1:
            self._show_initial_prompts_and_hypotheses(debate_result)
        
        with tab2:
            self._show_debate_rounds(debate_result)
        
        with tab3:
            self._show_final_optimal_prompt(debate_result)
        
        with tab4:
            self._show_debate_summary(debate_result)
    
    def _show_initial_prompts_and_hypotheses(self, debate_result: OptimalPromptDebateState):
        """1ë‹¨ê³„: ê° ì—ì´ì „íŠ¸ì˜ ì´ˆê¸° í”„ë¡¬í”„íŠ¸ì™€ ê°€ì„¤ í‘œì‹œ"""
        
        st.markdown("## ê° ì „ë¬¸ê°€ì˜ ì´ˆê¸° í”„ë¡¬í”„íŠ¸ ë° ìƒì„±ëœ ê°€ì„¤")
        st.markdown("*ê° ì „ë¬¸ê°€ê°€ ë…ë¦½ì ìœ¼ë¡œ ìƒì„±í•œ í”„ë¡¬í”„íŠ¸ì™€ ê·¸ í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±í•œ ê°€ì„¤ì…ë‹ˆë‹¤.*")
        
        for i, initial_data in enumerate(debate_result.initial_prompts_with_hypotheses, 1):
            
            # ì „ë¬¸ê°€ë³„ ìƒ‰ìƒ
            color_map = {
                "êµ¬ì¡°í™”í•™": "ğŸ”´",
                "ìƒì²´ë¶„ì ìƒí˜¸ì‘ìš©": "ğŸŸ¢", 
                "êµ¬ì¡°-í™œì„± ê´€ê³„ (SAR) í†µí•©": "ğŸ”µ"
            }
            icon = color_map.get(initial_data.expertise, "âšª")
            
            st.markdown(f"### {icon} {i}. {initial_data.expertise} ì „ë¬¸ê°€")
            
            # í”„ë¡¬í”„íŠ¸ í† ê¸€
            with st.expander(f"ğŸ“„ {initial_data.expertise} ì „ë¬¸ê°€ê°€ ìƒì„±í•œ í”„ë¡¬í”„íŠ¸", expanded=False):
                st.code(initial_data.initial_prompt, language="text")
            
            # ê°€ì„¤ í† ê¸€
            with st.expander(f"ğŸ§ª í•´ë‹¹ í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±ëœ ê°€ì„¤", expanded=False):
                st.markdown(initial_data.generated_hypothesis)
            
            st.markdown("---")
    
    def _show_debate_rounds(self, debate_result: OptimalPromptDebateState):
        """2ë‹¨ê³„: 3ë²ˆì˜ í† ë¡  ê³¼ì • í‘œì‹œ"""
        
        st.markdown("## í† ë¡  ê³¼ì • (3ë¼ìš´ë“œ)")
        st.markdown("*ê° ì „ë¬¸ê°€ì˜ í”„ë¡¬í”„íŠ¸ì™€ ê°€ì„¤ì— ëŒ€í•´ ë‹¤ë¥¸ ì „ë¬¸ê°€ë“¤ì´ ì§ì ‘ ì¸ìš©í•˜ë©° í‰ê°€í•©ë‹ˆë‹¤.*")
        
        for debate_round in debate_result.debate_rounds:
            
            # ë¼ìš´ë“œ í—¤ë”
            focus_expertise = next(
                (data.expertise for data in debate_result.initial_prompts_with_hypotheses 
                 if data.agent_name == debate_round.focus_agent), 
                "ì•Œ ìˆ˜ ì—†ìŒ"
            )
            
            st.markdown(f"### ğŸ”„ í† ë¡  {debate_round.round_number}ë¼ìš´ë“œ: {focus_expertise} ì „ë¬¸ê°€ ì§‘ì¤‘ í‰ê°€")
            
            with st.expander(f"í† ë¡  {debate_round.round_number}ë¼ìš´ë“œ ì „ì²´ ë³´ê¸°", expanded=False):
                
                # í‰ê°€ ëŒ€ìƒ í”„ë¡¬í”„íŠ¸ì™€ ê°€ì„¤ ë‹¤ì‹œ í‘œì‹œ
                st.markdown("#### ğŸ“‹ í‰ê°€ ëŒ€ìƒ")
                st.markdown("**í”„ë¡¬í”„íŠ¸:**")
                st.code(debate_round.focus_prompt[:500] + "..." if len(debate_round.focus_prompt) > 500 else debate_round.focus_prompt, language="text")
                
                st.markdown("**ìƒì„±ëœ ê°€ì„¤:**")
                st.info(debate_round.focus_hypothesis[:300] + "..." if len(debate_round.focus_hypothesis) > 300 else debate_round.focus_hypothesis)
                
                st.markdown("#### ğŸ—£ï¸ ì „ë¬¸ê°€ë“¤ì˜ í‰ê°€")
                
                # ê° í‰ê°€ìì˜ í‰ê°€ í‘œì‹œ
                for evaluation in debate_round.evaluations:
                    evaluator_expertise = evaluation.get('evaluator_expertise', 'ì•Œ ìˆ˜ ì—†ìŒ')
                    
                    st.markdown(f"##### ğŸ‘¨â€ğŸ”¬ {evaluator_expertise} ì „ë¬¸ê°€ì˜ í‰ê°€")
                    
                    # JSON íŒŒì‹±ëœ í‰ê°€
                    if 'praise_evaluations' in evaluation and evaluation['praise_evaluations']:
                        st.markdown("**âœ… ì¹­ì°¬ë°›ì€ ë¶€ë¶„ë“¤:**")
                        for j, praise in enumerate(evaluation['praise_evaluations'], 1):
                            st.success(f"""
**ì§ì ‘ ì¸ìš©**: "{praise.get('quoted_text', 'N/A')}"

**í‰ê°€ ì´ìœ **: {praise.get('reasoning', 'N/A')}

**ì ìˆ˜**: {praise.get('score', 'N/A')}/10
""")
                    
                    if 'criticism_evaluations' in evaluation and evaluation['criticism_evaluations']:
                        st.markdown("**âš ï¸ ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„ë“¤:**")
                        for j, criticism in enumerate(evaluation['criticism_evaluations'], 1):
                            st.warning(f"""
**ì§ì ‘ ì¸ìš©**: "{criticism.get('quoted_text', 'N/A')}"

**ë¬¸ì œì **: {criticism.get('reasoning', 'N/A')}

**ê°œì„  ì œì•ˆ**: {criticism.get('improvement_suggestion', 'N/A')}

**ì ìˆ˜**: {criticism.get('score', 'N/A')}/10
""")
                    
                    # ì „ì²´ í‰ê°€
                    if 'overall_assessment' in evaluation:
                        st.markdown("**ğŸ“ ì¢…í•© í‰ê°€:**")
                        st.markdown(evaluation['overall_assessment'])
                    
                    # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ í‘œì‹œ
                    if 'raw_evaluation' in evaluation:
                        with st.expander("ì›ë³¸ í‰ê°€ í…ìŠ¤íŠ¸ (íŒŒì‹± ì‹¤íŒ¨)"):
                            st.text(evaluation['raw_evaluation'])
                    
                    st.markdown("---")
            
            st.markdown("---")
    
    def _show_final_optimal_prompt(self, debate_result: OptimalPromptDebateState):
        """3ë‹¨ê³„: ìµœì¢… ìµœì  í”„ë¡¬í”„íŠ¸ ë° ê°€ì„¤ í‘œì‹œ"""
        
        st.markdown("## ğŸ† ìµœì¢… ìµœì  í”„ë¡¬í”„íŠ¸ ë° ê°€ì„¤")
        st.markdown("*í† ë¡  ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìƒì„±ëœ ìµœì¢… ìµœì  í”„ë¡¬í”„íŠ¸ì™€ ê·¸ê²ƒìœ¼ë¡œ ìƒì„±í•œ ê°€ì„¤ì…ë‹ˆë‹¤.*")
        
        if not debate_result.final_optimal_prompt:
            st.error("ìµœì¢… ìµœì  í”„ë¡¬í”„íŠ¸ê°€ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return
        
        # ìµœì¢… í”„ë¡¬í”„íŠ¸ ì „ë¬¸
        st.markdown("### ìµœì¢… ìµœì  í”„ë¡¬í”„íŠ¸ (ì „ë¬¸)")
        with st.container():
            st.markdown("#### ğŸ“„ í† ë¡ ì„ í†µí•´ ì œì•ˆëœ ìµœì  í”„ë¡¬í”„íŠ¸")
            st.code(debate_result.final_optimal_prompt, language="text")
        
        st.markdown("---")
        
        # ìµœì¢… ê°€ì„¤ ì „ë¬¸  
        st.markdown("### ìµœì¢… ê°€ì„¤ (ì „ë¬¸)")
        if debate_result.final_optimal_hypothesis:
            with st.container():
                st.markdown("#### ğŸ“„ ìµœì  í”„ë¡¬í”„íŠ¸ë¡œ ìƒì„±ëœ ìµœì¢… ê°€ì„¤")
                st.markdown(debate_result.final_optimal_hypothesis)
        else:
            st.warning("ìµœì¢… ê°€ì„¤ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        st.markdown("---")
        col1, col2 = st.columns(2)
        
        with col1:
            st.download_button(
                label="ğŸ“„ ìµœì¢… í”„ë¡¬í”„íŠ¸ ë‹¤ìš´ë¡œë“œ",
                data=debate_result.final_optimal_prompt,
                file_name="optimal_prompt.txt",
                mime="text/plain"
            )
        
        with col2:
            if debate_result.final_optimal_hypothesis:
                st.download_button(
                    label="ğŸ§ª ìµœì¢… ê°€ì„¤ ë‹¤ìš´ë¡œë“œ", 
                    data=debate_result.final_optimal_hypothesis,
                    file_name="optimal_hypothesis.txt",
                    mime="text/plain"
                )
    
    def _show_debate_summary(self, debate_result: OptimalPromptDebateState):
        """4ë‹¨ê³„: í† ë¡  ìš”ì•½ í†µê³„"""
        
        st.markdown("## ğŸ“Š í† ë¡  ìš”ì•½")
        
        # ê¸°ë³¸ í†µê³„
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("ì°¸ì—¬ ì „ë¬¸ê°€", len(debate_result.initial_prompts_with_hypotheses))
        
        with col2:
            st.metric("í† ë¡  ë¼ìš´ë“œ", len(debate_result.debate_rounds))
        
        with col3:
            total_duration = debate_result.end_time - debate_result.start_time
            st.metric("ì´ ì†Œìš”ì‹œê°„", f"{total_duration:.1f}ì´ˆ")
        
        with col4:
            error_count = len(debate_result.errors)
            st.metric("ì˜¤ë¥˜ ë°œìƒ", error_count, delta_color="inverse")
        
        # ì „ë¬¸ê°€ë³„ í‰ê°€ ë°›ì€ íšŸìˆ˜
        st.markdown("### ğŸ‘¥ ì „ë¬¸ê°€ë³„ í‰ê°€ í˜„í™©")
        
        evaluation_stats = {}
        for debate_round in debate_result.debate_rounds:
            focus_expertise = next(
                (data.expertise for data in debate_result.initial_prompts_with_hypotheses 
                 if data.agent_name == debate_round.focus_agent), 
                "ì•Œ ìˆ˜ ì—†ìŒ"
            )
            
            praise_count = 0
            criticism_count = 0
            
            for evaluation in debate_round.evaluations:
                praise_count += len(evaluation.get('praise_evaluations', []))
                criticism_count += len(evaluation.get('criticism_evaluations', []))
            
            evaluation_stats[focus_expertise] = {
                'praise': praise_count,
                'criticism': criticism_count
            }
        
        for expertise, stats in evaluation_stats.items():
            st.markdown(f"**{expertise}**:")
            col1, col2 = st.columns(2)
            with col1:
                st.success(f"ì¹­ì°¬: {stats['praise']}íšŒ")
            with col2:
                st.warning(f"ê°œì„ ì  ì§€ì : {stats['criticism']}íšŒ")
        
        # ì˜¤ë¥˜ ë¡œê·¸
        if debate_result.errors:
            st.markdown("### âš ï¸ ë°œìƒí•œ ì˜¤ë¥˜ë“¤")
            for error in debate_result.errors:
                st.error(error)
    
    def show_sample_interface(self):
        """ìƒ˜í”Œ ë°ì´í„°ë¡œ ì¸í„°í˜ì´ìŠ¤ í…ŒìŠ¤íŠ¸"""
        st.markdown("# ğŸ§ª ìµœì  í”„ë¡¬í”„íŠ¸ í† ë¡  ì‹œìŠ¤í…œ (ìƒ˜í”Œ í…ŒìŠ¤íŠ¸)")
        
        # ìƒ˜í”Œ Activity Cliff ë°ì´í„°
        sample_cliff = {
            'mol_1': {
                'ID': 'COMPOUND_001',
                'SMILES': 'CC1=CC=C(C=C1)NC2=NC=NC3=C2C=CN3',
                'pKi': 6.2
            },
            'mol_2': {
                'ID': 'COMPOUND_002',
                'SMILES': 'CC1=CC=C(C=C1)NC2=NC=NC3=C2C=CN3C4CCNCC4',
                'pKi': 8.5
            },
            'similarity': 0.85,
            'activity_diff': 2.3,
            'score': 1.95
        }
        
        st.info("ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
        self.show_interface(sample_cliff, target_name="ìƒ˜í”Œ íƒ€ê²Ÿ")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    interface = OptimalPromptDebateInterface()
    interface.show_sample_interface()

if __name__ == "__main__":
    main()